### **프로젝트 계획: 엣지 디바이스 기반 한국어 수화 인식 시스템 개발**

**최종 목표:** Raspberry Pi 5 (Hailo-8 & C270 웹캠)에서 한국어 수화를 실시간으로 인식하는 시스템 구축

---

### **I. 사전 조사 및 지식 습득 (Pre-Investigation & Knowledge Acquisition)**

이 단계는 프로젝트의 기반을 다지는 중요한 과정입니다.

*   **1.1. 비디오 압축 포맷 심층 이해**
    *   **목표:** MJPEG, H.264, H.265의 기본 원리, 압축 과정, 특히 DCT(Discrete Cosine Transform) 계수 추출 방식 및 의미 이해.
    *   **세부 태스크:**
        - 1.1.1. MJPEG, H.264, H.265 코덱별 압축 알고리즘 상세 조사.
        - 1.1.2. 각 코덱에서 DCT 계수가 생성되고 사용되는 방식 학습. (ex: I-frame, P-frame, B-frame에서의 DCT 활용)
        - 1.1.3. FFMpeg, OpenCV 등 라이브러리를 통해 압축된 비디오 스트림에서 DCT 계수를 직접 추출하는 방법론 조사. (예: `libavcodec` 등 저수준 API 활용 가능성)
        - 1.1.4. 특정 DCT 계수(예: DC 계수, 저주파 AC 계수)가 비디오 특징으로 활용될 수 있는 잠재성 분석.
    *   **필요 지식:** 디지털 비디오 처리, 신호 처리, 푸리에/DCT 변환.

*   **1.2. 엣지 AI 및 Hailo-8 NPU 심층 이해**
    *   **목표:** Hailo-8 NPU의 아키텍처, 지원 모델 형식, 개발 워크플로우, 최적화 기법을 숙지.
    *   **세부 태스크:**
        - 1.2.1. Hailo-8 SDK (HailoRT, Hailo Compiler) 문서 정독.
        - 1.2.2. Hailo-8이 지원하는 딥러닝 프레임워크 (TensorFlow, PyTorch, ONNX) 및 모델 변환 과정 이해.
        - 1.2.3. Hailo-8에서의 양자화(Quantization) 기법 및 성능 영향 조사. (Post-training Quantization, Quantization-aware Training)
        - 1.2.4. Hailo-8 예제 코드 및 데모 실행 분석.
    *   **필요 지식:** 엣지 컴퓨팅, 딥러닝 모델 최적화, 하드웨어 가속기 개념.

*   **1.3. 멀티모달 입력 및 ASL SOTA 모델 조사**
    *   **목표:** RGB, YCbCr, 랜드마크 데이터, DCT 계수 등 다양한 입력 방식을 활용하는 모델 아키텍처를 파악하고, 수화 인식 분야의 최신 연구 동향을 이해. **특히, 각 모달리티의 정보 기여도 대비 연산량 증가의 효율성 측면을 고려.**
    *   **세부 태스크:**
        - 1.3.1. ASL (American Sign Language) 및 기타 수화 인식 분야의 SOTA (State-Of-The-Art) 논문 및 구현체 조사. (Transformer-based, 3D CNN, TCN 등)
        - 1.3.2. RGB 비디오, Hand/Face/Pose 랜드마크, 키포인트 데이터를 동시에 활용하는 멀티모달 퓨전(Fusion) 전략 분석. (Early Fusion, Late Fusion, Feature-level Fusion 등)
        - 1.3.3. DCT 계수, YCbCr 채널과 같은 압축 도메인 특징을 입력으로 사용하는 딥러닝 모델 사례 연구 및 **각 모달리티 추가 시 연산량/정확도 트레이드오프 분석.** (만약 없다면 아이디어 구체화 및 예상 오버헤드 분석)
        - 1.3.4. MediaPipe (Hand, Face, Pose)와 같은 랜드마크 추출 라이브러리의 성능, 속도, 정확도 조사. (엣지 디바이스에서의 실행 가능성 고려)
    *   **필요 지식:** 딥러닝 모델 아키텍처 (CNN, RNN, Transformer), 멀티모달 딥러닝, 컴퓨터 비전 (자세 추정, 키포인트 검출).

---

### **II. 개발 환경 구축 및 초기 설정 (Development Environment Setup)**

*   **2.1. Raspberry Pi 5 초기 설정**
    *   **목표:** 라즈베리파이 OS 설치 및 최적화, 기본 개발 도구 설치.
    *   **세부 태스크:**
        - 2.1.1. Raspberry Pi OS (64-bit) 설치 및 SSH/VNC 설정.
        - 2.1.2. 필수 패키지 업데이트 및 설치 (`apt-get update`, `upgrade`).
        - 2.1.3. Python 3 및 `pip` 설치.
        - 2.1.4. Git 설치 및 설정.

*   **2.2. Hailo-8 개발 환경 구축**
    *   **목표:** Hailo-8 SDK 및 필요한 라이브러리 설치.
    *   **세부 태스크:**
        - 2.2.1. Hailo SDK (HailoRT, Hailo Compiler) 라즈베리파이용 설치.
        - 2.2.2. Hailo SDK 설치 확인 및 데모 프로그램 실행.
        - 2.2.3. Hailo 관련 Python 바인딩 및 예제 동작 확인.

*   **2.3. 카메라 스트림 테스트 및 성능 측정**
    *   **목표:** C270 웹캠에서 실시간 스트림 획득 및 비트레이트, 해상도, FPS 확인.
    *   **세부 태스크:**
        - 2.3.1. C270 웹캠 라즈베리파이에 연결 및 드라이버 확인. (`lsusb`, `v4l2-ctl`).
        - 2.3.2. OpenCV를 사용하여 C270 웹캠에서 영상 캡처 스크립트 작성.
        - 2.3.3. 다양한 해상도(예: 1280x720, 640x480) 및 FPS(예: 15, 30)에서 MJPEG/H.264 인코딩 시 예상 비트레이트 측정/추정. (OpenCV 내 인코더 사용 또는 `ffmpeg` 직접 연동)
        - 2.3.4. 라즈베리파이의 CPU/메모리 사용량 모니터링하며 스트리밍 부하 확인.

---

### **III. 데이터 전처리 및 특징 추출 (Data Preprocessing & Feature Extraction)**

*   **3.1. 원시 비디오 스트림 처리 파이프라인 구축**
    *   **목표:** 웹캠으로부터 데이터를 받아 전처리하는 기본 파이프라인 구성.
    *   **세부 태스크:**
        - 3.1.1. OpenCV를 이용한 실시간 프레임 캡처 모듈 개발.
        - 3.1.2. 프레임 리사이징, 정규화 등 기본 전처리 모듈 구현.

*   **3.2. DCT 계수 추출 모듈 개발**
    *   **목표:** 비디오 프레임 또는 압축 스트림에서 직접 DCT 계수를 추출하는 모듈 개발.
    *   **세부 태스크:**
        - 3.2.1. **(가장 중요하고 난이도 높음)** MJPEG, H.264, H.265 스트림에서 저수준으로 DCT 계수 블록을 추출하는 방법 연구 및 구현. (FFmpeg/libavcodec API 활용 또는 직접 파싱).
        - 3.2.2. 추출된 DCT 계수의 시각화 및 유효성 검증 (예: DCT 역변환하여 원본 프레임과 유사성 확인).
        - 3.2.3. 모델 입력에 적합하도록 DCT 계수를 특정 형태로 가공하는 방법 정의. (예: 특정 계수만 추출, 2D 이미지 형태로 변환).
        - 3.2.4. RGB 프레임을 YCbCr 색공간으로 변환 모듈 구현. (선택적)
    *   **필요 지식:** C/C++ 프로그래밍 (FFmpeg API 활용 시), 비디오 포맷 스펙, DCT 수학, 색 공간 변환.

*   **3.3. 멀티모달 랜드마크 추출 모듈 개발**
    *   **목표:** 한국어 수화 인식을 위한 핵심 입력 중 하나인 손/얼굴/포즈 랜드마크를 **Hailo-8 NPU 또는 라즈베리파이 환경에 최적화된 방식**으로 실시간 추출하고, 이를 SOTA 모델의 입력 형식에 맞게 가공.
    *   **배경 및 고민:** SOTA 수화 인식 모델들은 랜드마크 데이터(특히 손, 얼굴, 포즈 키포인트)를 주요 입력으로 활용합니다. MediaPipe는 이러한 랜드마크 추출에 널리 사용되지만, 그 자체로 Hailo-8 NPU에서 직접 구동하기는 어렵습니다. 따라서, MediaPipe가 사용하는 내부 모델들을 Hailo-8에 맞게 변환하거나, Hailo-8에 배포 가능한 다른 경량 랜드마크 추출 모델을 찾아 적용하는 방안, 또는 라즈베리파이의 CPU/GPU 자원을 활용하는 방안 등을 종합적으로 고려해야 합니다.

    *   **세부 태스크:**

        - **3.3.1. 랜드마크 추출 모델/방법론 조사 및 Hailo-8 호환성 평가**
            *   **목표:** MediaPipe의 내부 모델들(BlazeFace, BlazeHand, BlazePose 등)을 Hailo-8에 포팅할 가능성 및 다른 경량 랜드마크 모델들의 Hailo-8 호환성 심층 조사.
            *   **세부 내용:**
                - 3.3.1.1. **MediaPipe 내부 모델 분석:**
                    - MediaPipe가 사용하는 랜드마크 추출 모델들(TensorFlow Lite 또는 TensorFlow Graph)의 `.tflite` 또는 `.pb` 파일 추출 가능성 조사.
                    - 추출된 모델의 아키텍처 및 연산 종류 파악. (Convolution, Depthwise Convolution, Pointwise Convolution, FC Layer 등)
                    - **Hailo-8 Compiler를 통한 모델 변환/컴파일 가능성 사전 평가:** Hailo-8이 지원하지 않는 연산(unsupported ops)이 있는지 확인.
                    - 모델 크기 및 예상 NPU 연산량 추정.
                - 3.3.1.2. **대체 경량 랜드마크 추출 모델 조사:**
                    - MobileNet, EfficientNet 기반의 Keypoint Detection 모델, OpenPose, AlphaPose, HRNet의 경량 버전 등 라즈베리파이 및 NPU 환경에 적합할 수 있는 다른 오픈소스 랜드마크 추출 모델 아키텍처 및 구현체 탐색.
                    - 각 모델의 정확도, 연산 효율성, Pre-trained 모델 유무, Hailo-8 호환성(ONNX/TensorFlow -> Hailo 변환 가능성) 평가.
                - 3.3.1.3. **SOTA 수화 인식 모델의 랜드마크 활용 방식 이해:**
                    - ASL SOTA 모델들이 어떤 형태의 랜드마크 데이터를 입력으로 사용하는지 (예: 2D/3D 좌표, 정규화 방식, 관절 간 거리, 속도 벡터 등) 심층 분석.
                    - 우리가 추출할 랜드마크 데이터가 SOTA 모델의 입력 요구사항을 충족시킬 수 있는지 고민. (예: MediaPipe는 3D 좌표 제공)

        - **3.3.2. Hailo-8 또는 라즈베리파이 최적화 랜드마크 추출 모듈 구현**
            *   **목표:** 3.3.1 단계에서 결정된 최적의 모델/방법론을 바탕으로 실제 랜드마크 추출 파이프라인 구현.
            *   **세부 내용:**
                - 3.3.2.1. **(Hailo-8 NPU 활용 방안)**
                    - 조사된 MediaPipe 내부 모델 또는 다른 경량 랜드마크 모델을 Hailo-8 SDK를 사용하여 컴파일 및 양자화. (Post-training Quantization 우선 시도)
                    - 라즈베리파이에서 HailoRT API를 통해 컴파일된 랜드마크 모델을 로드하고 실시간 프레임에서 추론하여 랜드마크 좌표 추출.
                    - 각 랜드마크(손, 얼굴, 포즈) 별로 Hailo-8에 최적화된 별도 모델을 구동하거나, 하나의 통합 모델을 사용하는 전략 수립.
                - 3.3.2.2. **(라즈베리파이 CPU/GPU 활용 방안 - Hailo-8 불가 시 또는 보조 역할)**
                    - 만약 Hailo-8에 랜드마크 모델 전체를 올리는 것이 불가능하거나 비효율적이라면, 라즈베리파이의 CPU 또는 온보드 GPU (VideoCore)를 활용하는 방안 검토.
                    - `OpenCV`의 DNN 모듈을 통해 `TensorFlow Lite` 또는 `ONNX` 형식의 경량 랜드마크 모델을 CPU/GPU에서 구동 테스트. (단, 실시간 성능에 제약이 있을 수 있음)
                    - **성능/정확도 트레이드오프 분석:** Hailo-8 vs. CPU/GPU 실행 시 속도, 전력 소모, 정확도 간의 균형점 파악.
                - 3.3.2.3. 비디오 프레임에서 랜드마크 추출 (프레임 캡처 -> 리사이징 -> 모델 추론).
                - 3.3.2.4. 추출된 랜드마크 데이터의 유효성 검증 (시각화 및 값 범위 확인).

        - **3.3.3. 추출된 랜드마크 데이터 모델 입력 형식으로 가공**
            *   **목표:** 추출된 랜드마크 데이터를 SOTA 수화 인식 모델들이 요구하는 형태로 정규화, 변환, 시퀀스화.
            *   **세부 내용:**
                - 3.3.3.1. **정규화:** 화면 해상도, 카메라 위치 등에 독립적인 랜드마크 좌표 정규화 (예: 특정 신체 부위를 기준으로 상대 좌표 계산, [-1, 1] 범위로 스케일링).
                - 3.3.3.2. **특징 선택:** SOTA 모델에서 주로 사용되는 핵심 랜드마크 키포인트 (예: 손가락 끝, 주요 관절, 코, 어깨 등) 선별.
                - 3.3.3.3. **시퀀스 데이터 변환:** 일정 프레임 수(예: 30프레임)의 랜드마크 시퀀스를 하나의 입력으로 구성 (예: (Batch_size, Sequence_length, Num_landmarks * Coord_dim) 형태).
                - 3.3.3.4. **추가 특징 생성:** 랜드마크 좌표 외에 SOTA 모델에서 활용되는 추가적인 특징 (예: 랜드마크 간 거리, 속도, 가속도, 각도) 계산 및 통합.
                - 3.3.3.5. 데이터셋에 적용하여 실제 모델 학습에 사용될 수 있는 형태로 파일 저장.

        - **3.3.4. 라즈베리파이/Hailo-8 성능 부하 측정 및 병목 분석**
            *   **목표:** 랜드마크 추출 모듈 구동 시 라즈베리파이의 시스템 자원 사용량 및 실시간 처리 성능 측정.
            *   **세부 내용:**
                - 3.3.4.1. 랜드마크 추출 파이프라인 구동 시 CPU, RAM, Hailo-8 NPU 사용률 모니터링.
                - 3.3.4.2. **엔드-투-엔드 Latency 측정:** 카메라 입력 -> 랜드마크 추출 완료까지의 시간 측정.
                - 3.3.4.3. **FPS 측정:** 초당 처리 가능한 프레임 수 측정.
                - 3.3.4.4. 측정 결과를 바탕으로 병목 현상이 발생하는 지점 (예: 모델 추론 시간, 데이터 전처리 시간) 파악 및 개선 방안 모색. (예: 입력 해상도 조정, 모델 경량화 추가)

---

*   **3.4. 데이터셋 통합 및 정제 (데이터 증강 전략 심화)**
    *   **목표:** 기존 데이터셋과 새로 추출된 멀티모달 특징 데이터를 통합하고, 다양한 데이터 증강 기법을 적용하여 학습 효율성 및 모델 강건성 확보.
    *   **세부 태스크:**
        - 3.4.1. 기존 한국어 수화 데이터셋에 추출된 DCT 계수, RGB, YCbCr, 랜드마크 데이터를 매칭 및 통합.
        - **3.4.2. 다양한 데이터 증강 기법 (회전, 패딩, 플리핑, 색상 변화, 시간적 증강 등) 조사 및 적용 전략 수립.**
            - 3.4.2.1. **비디오/이미지 증강 기법 조사:** 회전(Rotation), 크롭(Cropping), 패딩(Padding), 플리핑(Flipping), 색상/밝기 조절, 노이즈 추가 등 시각 데이터에 적용 가능한 증강 기법 심층 조사.
            - 3.4.2.2. **랜드마크 데이터 증강 기법 조사:** 랜드마크 좌표에 대한 기하학적 변환 (회전, 스케일링, 이동), 노이즈 추가 등 조사.
            - 3.4.2.3. **시간적 증강 기법 조사:** 비디오 시퀀스 길이 조절(프레임 샘플링, 속도 변화), 프레임 드롭 등 시퀀스 데이터에 특화된 증강 기법 조사.
            - 3.4.2.4. **증강 기법 조합 및 파이프라인 설계:** 각 모달리티 (RGB, YCbCr, DCT, 랜드마크)에 적합한 증강 기법을 선정하고 효율적인 적용 파이프라인 구축.
            - 3.4.2.5. **증강 기법 적용 전후 데이터셋 특성 분석 및 모델 성능 기여도 평가 방안 마련.** (예: 증강된 데이터셋으로 학습 시 정확도, 강건성 향상 여부)
        - 3.4.3. 데이터셋 불균형 확인 및 추가적인 균형화 기법 적용 (필요시).
        - 3.4.4. 학습/검증/테스트 셋 분리 및 최종 데이터셋 준비.

---

### **IV. 모델 아키텍처 설계 및 구현 (Model Architecture Design & Implementation)**

*   **4.1. ASL SOTA 모델 기반 아키텍처 구상**
    *   **목표:** 조사한 SOTA 모델들을 바탕으로 초기 한국어 수화 인식 모델 아키텍처 설계. **각 멀티모달 입력의 연산량-정확도 트레이드오프를 고려하여 최종 입력 모달리티를 결정.**
    *   **세부 태스크:**
        - 4.1.1. RGB, YCbCr, DCT 계수, 랜드마크 데이터를 각각 처리하는 서브 네트워크 아키텍처 설계. (예: 3D CNN for RGB/YCbCr, 2D CNN or MLP for DCT, TCN/LSTM for landmarks).
        - 4.1.2. 각 서브 네트워크의 출력을 통합하는 퓨전 전략 결정 및 설계. (예: Concat 후 FC 레이어, Attention 메커니즘 활용). **이때, 각 모달리티의 정보 기여도와 Hailo-8 NPU의 연산 제약을 고려하여 가장 효율적인 퓨전 방안 모색.** (예: 불필요한 모달리티 제거 또는 경량화)
        - 4.1.3. 전체 모델의 시퀀스 처리 방식 결정 (예: RNN, Transformer 인코더).

*   **4.2. 모델 구현 및 초기 학습**
    *   **목표:** 설계된 아키텍처를 PyTorch로 구현하고 초기 학습.
    *   **세부 태스크:**
        - 4.2.1. PyTorch 기반 모델 코드 작성.
        - 4.2.2. 데이터 로더 및 학습 파이프라인 구현.
        - 4.2.3. Server(A6000) 환경에서 초기 모델 학습 및 성능 검증.
        - 4.2.4. 모델 크기, 연산량 등 Hailo-8 배포 가능성 고려. (초기에는 큰 모델로 시도 후 경량화)

---

### **V. 엣지 디바이스 배포 및 성능 검증 (Edge Deployment & Performance Verification)**

*   **5.1. Hailo-8 최적화 및 컴파일**
    *   **목표:** 학습된 모델을 Hailo-8 NPU에 최적화하여 컴파일.
    *   **세부 태스크:**
        - 5.1.1. 학습된 PyTorch 모델을 ONNX 또는 TensorFlow Lite 형식으로 변환. (PyTorch를 사용하는 경우)
        - 5.1.2. Hailo Compiler를 사용하여 모델을 Hailo 아키텍처에 맞게 컴파일 및 양자화. (Post-training Quantization 우선 시도, 필요 시 Quantization-aware Training).
        - 5.1.3. Hailo Compilation Report 분석 및 최적화 기법 적용 (예: Layer Fusion, Batch Normalization Folding).
    *   **필요 지식:** 모델 양자화, Hailo Compiler 사용법.

*   **5.2. Hailo-8 온디바이스 추론 및 통합**
    *   **목표:** 라즈베리파이에서 Hailo-8을 사용하여 모델을 실시간으로 구동.
    *   **세부 태스크:**
        - 5.2.1. 컴파일된 모델을 라즈베리파이로 전송.
        - 5.2.2. HailoRT API를 사용하여 모델 로드 및 추론 테스트.
        - 5.2.3. 웹캠 스트림 캡처 -> 전처리 -> DCT/랜드마크/RGB/YCbCr 추출 -> Hailo-8 추론 -> 결과 후처리까지 엔드-투-엔드 파이프라인 통합.
        - 5.2.4. 전체 시스템의 실시간 추론 속도 (FPS), 지연 시간 (Latency) 측정.
        - 5.2.5. 라즈베리파이의 CPU/RAM/NPU 사용량 모니터링.

*   **5.3. 성능 분석 및 엣지 가능성 판단**
    *   **목표:** Hailo-8에서의 실제 성능이 요구 수준에 부합하는지 평가.
    *   **세부 태스크:**
        - 5.3.1. 측정된 FPS, Latency, 정확도 등을 종합하여 "엣지 디바이스에서 독립 실행 가능 여부" 판단.
        - 5.3.2. 병목 현상 발생 지점 파악 및 최적화 방안 모색 (예: 입력 해상도 조정, 모델 경량화, 전처리 최적화). **특히 멀티모달 입력 중 어떤 조합이 가장 효율적인 성능을 내는지 최종 판단.**
        - 5.3.3. **(결정)** Hailo-8 단독으로 목표 성능 달성 가능 시 다음 단계로 진행 / 불가능 시 PC 오프로딩 방안으로 전환.

---

### **VI. 비상 계획: PC 오프로딩 구현 및 테스트 (Contingency Plan: PC Offloading)**

Hailo-8 단독으로 목표 성능 달성이 불가능할 경우를 대비한 단계입니다.

*   **6.1. RPi -> PC 비디오 스트림 전송 모듈 개발**
    *   **목표:** 라즈베리파이에서 PC로 실시간 비디오 스트림을 효율적으로 전송.
    *   **세부 태스크:**
        - 6.1.1. 유무선 네트워크 연결 설정 (1000Mbps LAN 또는 10Mbps WiFi 성능 테스트).
        - 6.1.2. RTSP, RTMP 또는 커스텀 TCP/UDP 스트리밍 프로토콜 조사 및 구현. (FFmpeg 사용 고려).
        - 6.1.3. 스트리밍 시 비디오 압축(H.264/H.265) 및 비트레이트 조절 테스트.
        - 6.1.4. 네트워크 지연 시간 및 처리량 측정.

*   **6.2. PC(B580, Intel GPU) 기반 추론 시스템 구축**
    *   **목표:** PC에서 전송받은 비디오 스트림을 처리하고 모델 추론.
    *   **세부 태스크:**
        - 6.2.1. PC에 딥러닝 개발 환경 (PyTorch/TensorFlow, CUDA, cuDNN 또는 Intel OpenVINO) 구축.
        - 6.2.2. 라즈베리파이에서 전송받은 스트림을 디코딩하고 프레임 획득 모듈 개발.
        - 6.2.3. PC에서 DCT 계수, RGB, YCbCr 및 랜드마크 추출 모듈 실행.
        - 6.2.4. PC에서 학습된 모델을 로드하여 추론. (Intel GPU를 OpenVINO 등으로 활용 가능성 검토)

*   **6.3. PC -> RPi 추론 결과 전송 및 통합**
    *   **목표:** PC에서 얻은 추론 결과를 다시 라즈베리파이로 전송하고 시스템에 통합.
    *   **세부 태스크:**
        - 6.3.1. PC에서 라즈베리파이로 추론 결과 (예: 인식된 수화 단어, 확률)를 전송하는 통신 모듈 개발 (TCP/UDP 소켓).
        - 6.3.2. 라즈베리파이에서 전송받은 결과를 화면에 표시하거나 다음 동작을 트리거하는 모듈 구현.
        - 6.3.3. 전체 오프로딩 시스템의 엔드-투-엔드 지연 시간 측정 (카메라 캡처 -> PC 추론 -> RPi 결과 표시).
        - 6.3.4. 네트워크 대역폭, 지연 시간이 최종 성능에 미치는 영향 분석.

---

### **VII. 평가 및 반복 (Evaluation & Iteration)**

*   **7.1. 최종 시스템 성능 평가**
    *   **목표:** 개발된 시스템의 정확도, 속도, 안정성 종합 평가.
    *   **세부 태스크:**
        - 7.1.1. 테스트 데이터셋을 활용한 최종 인식 정확도 측정.
        - 7.1.2. 사용자 경험(UX) 측면에서의 반응 속도, 부드러움 평가.
        - 7.1.3. 장시간 구동 시 안정성 및 자원 소모량 모니터링.

*   **7.2. 개선 및 최적화**
    *   **목표:** 평가 결과를 바탕으로 시스템 개선 및 성능 최적화.
    *   **세부 태스크:**
        - 7.2.1. 에러 분석: 어떤 수화에서 오류가 발생하는지, 왜 발생하는지 분석.
        - 7.2.2. 모델 재학습, 데이터 증강 전략 보완, 전처리 개선 등 반복 적용.
        - 7.2.3. 하드웨어/소프트웨어 병목 현상 재조사 및 해결.

---

### **VIII. 프로젝트 관리 및 문서화 (Project Management & Documentation)**

*   **8.1. 태스크 관리**
    *   **목표:** 모든 태스크를 체계적으로 관리하고 진행 상황을 추적.
    *   **세부 태스크:**
        - 8.1.1. 노션 또는 깃 이슈(GitHub Issues)에 위 태스크들을 생성하고 할당.
        - 8.1.2. 각 태스크별 목표, 예상 시간, 실제 시간, 상태 (To Do, In Progress, Done), 우선순위 설정.
        - 8.1.3. 정기적인 진행 상황 업데이트 및 공유.

*   **8.2. 코드 버전 관리**
    *   **목표:** 깃을 활용하여 코드 변경 사항을 체계적으로 관리.
    *   **세부 태스크:**
        - 8.2.1. 깃 레포지토리 생성 및 초기 설정.
        - 8.2.2. 기능별 브랜치 전략 수립 및 활용.
        - 8.2.3. 커밋 메시지 규칙 준수.

*   **8.3. 기술 문서화**
    *   **목표:** 프로젝트의 모든 중요한 결정, 구현 상세, 실험 결과 등을 기록.
    *   **세부 태스크:**
        - 8.3.1. 시스템 아키텍처 다이어그램 작성.
        - 8.3.2. 데이터 전처리 및 특징 추출 로직 상세 문서화.
        - 8.3.3. 모델 학습 과정, 하이퍼파라미터, 성능 결과 기록.
        - 8.3.4. 엣지 디바이스 배포 및 최적화 과정, 발생한 문제와 해결책 기록.
        - 8.3.5. PC 오프로딩 방안의 구현 상세 및 성능 분석 기록.

---