#!/usr/bin/env python3
"""
Batch Fast Multi-ONNX Processor - GPU 배치 256 최적화 버전 (완전 개선)
Phase 1: 배치 처리 아키텍처 구축 ⚡ - 256 프레임씩 VRAM 미리 로드, A6000 x2 완전 활용
Phase 2: 성능 모니터링 시스템 📊 - 실시간 진행률, GPU 사용률, FPS 통계
Phase 3: 고속 파이프라인 구현 🚀 - 비동기 로딩, 스트리밍 처리, 결과 버퍼링
"""

import os
import cv2
import h5py
import time
import json
import torch
import queue
import logging
import threading
import traceback
import numpy as np
import multiprocessing as mp
from pathlib import Path
from tqdm import tqdm
from typing import List, Dict, Tuple, Optional, Union
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from collections import deque
from datetime import datetime
import psutil
import GPUtil
import argparse
import sys

from onnx_inferencer import YOLO11LRTMWONNXInferencer as ONNXInferencer

# ===== RTMW 전처리 함수들 (streamlined_processor.py 참고) =====

def bbox_xyxy2cs(bbox: np.ndarray, padding: float = 1.10) -> Tuple[np.ndarray, np.ndarray]:
    """바운딩박스를 center, scale로 변환 (패딩 1.10으로 수정)"""
    dim = bbox.ndim
    if dim == 1:
        bbox = bbox[None, :]
    
    scale = (bbox[..., 2:] - bbox[..., :2]) * padding
    center = (bbox[..., 2:] + bbox[..., :2]) * 0.5
    
    if dim == 1:
        center = center[0]
        scale = scale[0]
    
    return center, scale

def _rotate_point(pt: np.ndarray, angle_rad: float) -> np.ndarray:
    """점을 회전"""
    cos_val = np.cos(angle_rad)
    sin_val = np.sin(angle_rad)
    return np.array([pt[0] * cos_val - pt[1] * sin_val,
                     pt[0] * sin_val + pt[1] * cos_val])

def _get_3rd_point(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    """세 번째 점을 계산 (직교점)"""
    direction = a - b
    return b + np.array([-direction[1], direction[0]])

def get_warp_matrix(center: np.ndarray, scale: np.ndarray, rot: float, 
                   output_size: Tuple[int, int]) -> np.ndarray:
    """아핀 변환 매트릭스 계산"""
    src_w, src_h = scale[:2]
    dst_w, dst_h = output_size[:2]
    
    rot_rad = np.deg2rad(rot)
    src_dir = _rotate_point(np.array([src_w * -0.5, 0.]), rot_rad)
    dst_dir = np.array([dst_w * -0.5, 0.])
    
    src = np.zeros((3, 2), dtype=np.float32)
    src[0, :] = center
    src[1, :] = center + src_dir
    
    dst = np.zeros((3, 2), dtype=np.float32)
    dst[0, :] = [dst_w * 0.5, dst_h * 0.5]
    dst[1, :] = np.array([dst_w * 0.5, dst_h * 0.5]) + dst_dir
    
    # aspect ratio 고정
    src[2, :] = _get_3rd_point(src[0, :], src[1, :])
    dst[2, :] = _get_3rd_point(dst[0, :], dst[1, :])
    
    warp_mat = cv2.getAffineTransform(src, dst)
    return warp_mat

def fix_aspect_ratio(bbox_scale: np.ndarray, aspect_ratio: float) -> np.ndarray:
    """bbox를 고정 종횡비로 조정"""
    w, h = bbox_scale[0], bbox_scale[1]
    if w > h * aspect_ratio:
        new_h = w / aspect_ratio
        bbox_scale = np.array([w, new_h])
    else:
        new_w = h * aspect_ratio
        bbox_scale = np.array([new_w, h])
    return bbox_scale

# ===== Phase 1: 배치 처리 아키텍처 구축 ⚡ =====

@dataclass
class BatchMetrics:
    """배치 처리 메트릭스"""
    frames_processed: int = 0
    processing_time: float = 0.0
    gpu_memory_used: float = 0.0
    throughput_fps: float = 0.0
    batch_id: int = 0
    gpu_id: int = 0

class SmartVRAMBuffer:
    """스마트 VRAM 버퍼링 시스템"""
    
    def __init__(self, gpu_id: int, batch_size: int = 256, max_vram_usage: float = 0.85):
        self.gpu_id = gpu_id
        self.batch_size = batch_size
        self.max_vram_usage = max_vram_usage
        self.device = f"cuda:{gpu_id}"
        
        # GPU 메모리 정보
        torch.cuda.set_device(gpu_id)
        gpu_props = torch.cuda.get_device_properties(gpu_id)
        self.total_vram = gpu_props.total_memory / (1024**3)
        self.max_vram = self.total_vram * max_vram_usage
        
        # 프레임 배치 버퍼 (VRAM에 미리 로드)
        single_frame_size = 384 * 288 * 3 * 4  # float32
        self.batch_memory_mb = (single_frame_size * batch_size) / (1024 * 1024)
        
        print(f"🚀 SmartVRAMBuffer GPU {gpu_id} 초기화")
        print(f"   - 총 VRAM: {self.total_vram:.1f}GB")
        print(f"   - 최대 사용: {self.max_vram:.1f}GB")
        print(f"   - 배치 메모리: {self.batch_memory_mb:.1f}MB")
        
    def preload_batch(self, frames: List[np.ndarray]) -> torch.Tensor:
        """프레임 배치를 VRAM에 미리 로드"""
        batch_size = min(len(frames), self.batch_size)
        
        with torch.cuda.device(self.device):
            batch_tensor = torch.zeros((batch_size, 3, 384, 288), 
                                     dtype=torch.float32, device=self.device)
            
            for i, frame in enumerate(frames[:batch_size]):
                if frame is not None:
                    # OpenCV (H,W,C) -> PyTorch (C,H,W) 변환
                    frame_tensor = torch.from_numpy(frame.transpose(2, 0, 1)).float()
                    batch_tensor[i] = frame_tensor.to(self.device) / 255.0
            
            return batch_tensor
    
    def get_memory_usage(self) -> Dict[str, float]:
        """현재 GPU 메모리 사용량 반환"""
        allocated = torch.cuda.memory_allocated(self.device) / (1024**3)
        reserved = torch.cuda.memory_reserved(self.device) / (1024**3)
        return {
            'allocated': allocated,
            'reserved': reserved,
            'usage_percent': (allocated / self.total_vram) * 100
        }

# ===== Phase 2: 성능 모니터링 시스템 📊 =====

class PerformanceMonitor:
    """실시간 성능 모니터링 시스템"""
    
    def __init__(self):
        self.metrics_history = deque(maxlen=100)  # 최근 100개 배치 기록
        self.start_time = time.time()
        self.frame_count = 0
        self.batch_count = 0
        
        # GPU 모니터링 초기화
        try:
            self.gpus = GPUtil.getGPUs()
        except:
            self.gpus = []
        
    def log_batch_metrics(self, metrics: BatchMetrics):
        """배치 메트릭스 기록"""
        self.metrics_history.append(metrics)
        self.frame_count += metrics.frames_processed
        self.batch_count += 1
        
    def get_realtime_stats(self) -> Dict:
        """실시간 통계 반환"""
        if not self.metrics_history:
            return {}
        
        recent_metrics = list(self.metrics_history)[-10:]  # 최근 10개 배치
        
        avg_fps = np.mean([m.throughput_fps for m in recent_metrics])
        avg_gpu_usage = np.mean([m.gpu_memory_used for m in recent_metrics])
        
        total_time = time.time() - self.start_time
        overall_fps = self.frame_count / max(total_time, 0.001)
        
        # GPU 상태 조회
        gpu_stats = []
        for gpu in self.gpus:
            gpu_stats.append({
                'id': gpu.id,
                'name': gpu.name,
                'memory_used': gpu.memoryUsed,
                'memory_total': gpu.memoryTotal,
                'memory_percent': gpu.memoryUtil * 100,
                'gpu_util': gpu.load * 100
            })
        
        return {
            'batch_count': self.batch_count,
            'total_frames': self.frame_count,
            'avg_fps_recent': avg_fps,
            'overall_fps': overall_fps,
            'avg_gpu_memory': avg_gpu_usage,
            'total_processing_time': total_time,
            'gpu_stats': gpu_stats,
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent
        }
    
    def print_progress(self):
        """진행 상황 출력"""
        stats = self.get_realtime_stats()
        if stats:
            print(f"\n📊 실시간 성능 통계:")
            print(f"   - 처리된 배치: {stats['batch_count']}")
            print(f"   - 총 프레임: {stats['total_frames']}")
            print(f"   - 전체 FPS: {stats['overall_fps']:.1f}")
            print(f"   - 최근 평균 FPS: {stats['avg_fps_recent']:.1f}")
            print(f"   - CPU 사용률: {stats['cpu_percent']:.1f}%")
            print(f"   - 메모리 사용률: {stats['memory_percent']:.1f}%")
            
            for gpu_stat in stats['gpu_stats']:
                print(f"   - GPU {gpu_stat['id']} ({gpu_stat['name']}): "
                      f"VRAM {gpu_stat['memory_percent']:.1f}%, "
                      f"사용률 {gpu_stat['gpu_util']:.1f}%")

# ===== Phase 3: 고속 파이프라인 구현 🚀 =====

class AsyncDataLoader:
    """비동기 데이터 로딩 시스템"""
    
    def __init__(self, max_queue_size: int = 4):
        self.max_queue_size = max_queue_size
        self.data_queue = queue.Queue(maxsize=max_queue_size)
        self.loading_thread = None
        self.is_loading = False
        
    def start_loading(self, video_paths: List[str]):
        """비동기 데이터 로딩 시작"""
        self.is_loading = True
        self.loading_thread = threading.Thread(
            target=self._load_videos_async,
            args=(video_paths,),
            daemon=True
        )
        self.loading_thread.start()
        
    def _load_videos_async(self, video_paths: List[str]):
        """비동기로 비디오 로딩"""
        for video_path in video_paths:
            if not self.is_loading:
                break
                
            try:
                # 간단한 비디오 정보만 로드 (실제 프레임은 나중에)
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    video_info = {
                        'path': video_path,
                        'fps': cap.get(cv2.CAP_PROP_FPS),
                        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                        'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    }
                    cap.release()
                    self.data_queue.put(video_info, timeout=10)
                else:
                    cap.release()
            except queue.Full:
                print(f"⚠️ 큐가 가득찬, 비디오 스킵: {video_path}")
                continue
            except Exception as e:
                print(f"❌ 비디오 정보 로딩 실패: {video_path} - {e}")
                continue
    
    def get_next_video_info(self, timeout: float = 5.0) -> Optional[Dict]:
        """다음 비디오 정보 가져오기"""
        try:
            return self.data_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def stop_loading(self):
        """로딩 중지"""
        self.is_loading = False
        if self.loading_thread and self.loading_thread.is_alive():
            self.loading_thread.join(timeout=2)

class BatchFastVideoProcessor:
    """배치 고속 비디오 처리기 - GPU 배치 256 최적화 (완전 개선)"""
    
    def __init__(self, 
                 rtmw_model_name: str = "rtmw-dw-x-l_simcc-cocktail14_270e-384x288.onnx",
                 gpu_id: int = 0,
                 batch_size: int = 256,
                 keypoint_scale: int = 8,
                 jpeg_quality: int = 90,
                 max_vram_usage: float = 0.85):
        
        self.rtmw_model_name = rtmw_model_name
        self.gpu_id = gpu_id
        self.batch_size = batch_size
        self.keypoint_scale = keypoint_scale
        self.jpeg_quality = jpeg_quality
        self.max_vram_usage = max_vram_usage
        self.device = f"cuda:{gpu_id}"
        
        # Phase 1: 스마트 VRAM 버퍼 초기화
        self.vram_buffer = SmartVRAMBuffer(
            gpu_id=gpu_id, 
            batch_size=batch_size,
            max_vram_usage=max_vram_usage
        )
        
        # Phase 2: 성능 모니터링 초기화
        self.monitor = PerformanceMonitor()
        
        # GPU 설정
        torch.cuda.set_device(gpu_id)
        
        try:
            # ONNX 추론기 초기화
            self.inferencer = ONNXInferencer(
                rtmw_onnx_path=rtmw_model_name,
                detection_device=self.device,
                pose_device=self.device,
                optimize_for_accuracy=True
            )
            
            print(f"🚀 BatchFastVideoProcessor GPU {gpu_id} 초기화 완료")
            print(f"   - 디바이스: {self.device}")
            print(f"   - 배치 크기: {batch_size}")
            print(f"   - RTMW 모델: {rtmw_model_name}")
            
            # GPU 워밍업
            self._warmup_gpu()
            
        except Exception as e:
            print(f"❌ BatchFastVideoProcessor 초기화 실패: {e}")
            raise
    
    def _warmup_gpu(self):
        """GPU 워밍업 - 배치 처리 최적화"""
        print(f"🔥 GPU 워밍업 시작 (배치 {self.batch_size})")
        start_time = time.time()
        
        try:
            # 더미 배치 텐서 생성
            dummy_batch = torch.randn(self.batch_size, 3, 384, 288).cuda()
            
            # 몇 번 연산 수행하여 GPU 활성화
            for _ in range(3):
                _ = dummy_batch * 2.0
                _ = torch.nn.functional.interpolate(dummy_batch, size=(288, 384))
            
            # 메모리 정리
            del dummy_batch
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
            
            warmup_time = time.time() - start_time
            vram_used = torch.cuda.memory_allocated() / 1024**3
            
            print(f"✅ GPU 워밍업 완료: {warmup_time:.2f}초")
            print(f"   - VRAM 사용: {vram_used:.2f}GB")
            print(f"   - 배치 텐서: {self.batch_size} x 3 x 384 x 288")
            
        except Exception as e:
            print(f"⚠️ GPU 워밍업 실패: {e}")

    def process_video_batch_optimized(self, video_path: str, progress_callback=None) -> Optional[Dict]:
        """배치 최적화된 비디오 처리 - Production Ready"""
        start_total_time = time.time()
        
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"❌ 비디오 열기 실패: {video_path}")
                return None
            
            # 전체 프레임 수 계산
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if total_frames == 0:
                cap.release()
                return None
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            print(f"📹 비디오 정보: {total_frames}프레임, {fps:.2f}FPS, {width}x{height}")
            
            # 메모리 효율적 프레임 로딩
            frames = []
            frame_count = 0
            
            # 프레임 로딩 with 진행률
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frames.append(frame)
                frame_count += 1
                
                # 진행률 콜백
                if progress_callback and frame_count % 50 == 0:
                    progress = min(frame_count / total_frames * 0.3, 0.3)  # 로딩 30%
                    progress_callback(progress)
            
            cap.release()
            actual_frame_count = len(frames)
            
            if actual_frame_count == 0:
                print(f"❌ 유효한 프레임 없음: {video_path}")
                return None
            
            print(f"✅ 프레임 로드 완료: {actual_frame_count}개 (배치 {self.batch_size}로 처리)")
            
            # 결과 저장 리스트
            jpeg_frames = []
            keypoints_list = []
            scores_list = []
            
            # 배치별로 처리
            batch_frames = []
            batch_start_time = time.time()
            processed_frames = 0
            
            for frame_idx, frame in enumerate(frames):
                batch_frames.append(frame)
                
                # 배치가 찼거나 마지막 프레임인 경우
                if len(batch_frames) >= self.batch_size or frame_idx == len(frames) - 1:
                    
                    # GPU 배치 처리 실행
                    batch_results = self._process_frame_batch(batch_frames)
                    
                    # 결과 저장 및 JPEG 인코딩 (streamlined 방식: 크롭 이미지 저장)
                    for i, (frame, result) in enumerate(zip(batch_frames, batch_results)):
                        
                        if result and len(result) == 3:
                            frame_keypoints, frame_scores, crop_image = result
                            
                            # streamlined 방식: 크롭 이미지를 JPEG로 인코딩
                            if crop_image is not None:
                                # 크롭 이미지 JPEG 인코딩 (streamlined와 동일)
                                encode_params = [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality]
                                success, buffer = cv2.imencode('.jpg', crop_image, encode_params)
                                
                                if success:
                                    jpeg_frames.append(buffer)  # numpy 배열 직접 저장
                                else:
                                    # 폴백: 기본 인코딩
                                    _, buffer = cv2.imencode('.jpg', crop_image)
                                    jpeg_frames.append(buffer)
                            else:
                                # 크롭 이미지가 없는 경우 원본 프레임 사용
                                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality])
                                jpeg_frames.append(buffer)
                        else:
                            # 검출 결과 없는 경우 원본 프레임 사용
                            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality])
                            jpeg_frames.append(buffer)
                        
                        # 키포인트 데이터 처리
                        if result and len(result) >= 2:
                            frame_keypoints, frame_scores = result[0], result[1]
                            
                            # 키포인트 스케일링
                            if len(frame_keypoints) > 0 and self.keypoint_scale != 1:
                                scaled_keypoints = []
                                for person_kpts in frame_keypoints:
                                    if isinstance(person_kpts, (list, np.ndarray)) and len(person_kpts) > 0:
                                        scaled_kpts = []
                                        for j in range(0, len(person_kpts), 2):
                                            if j + 1 < len(person_kpts):
                                                x = int(person_kpts[j] * self.keypoint_scale)
                                                y = int(person_kpts[j + 1] * self.keypoint_scale)
                                                scaled_kpts.extend([x, y])
                                        scaled_keypoints.append(scaled_kpts)
                                    else:
                                        scaled_keypoints.append(person_kpts)
                                keypoints_list.append(scaled_keypoints)
                            else:
                                keypoints_list.append(frame_keypoints)
                            
                            scores_list.append(frame_scores)
                        else:
                            # 기본값 (검출된 사람 없음)
                            keypoints_list.append([[0] * 34])  # 17개 키포인트 * 2 (x,y)
                            scores_list.append([0.0])
                    
                    processed_frames += len(batch_frames)
                    
                    # 진행률 업데이트
                    if progress_callback:
                        progress = 0.3 + (processed_frames / actual_frame_count) * 0.7  # 30% + 처리 70%
                        progress_callback(min(progress, 1.0))
                    
                    # 배치 초기화
                    batch_frames = []
                    
                    # GPU 메모리 정리 (주기적)
                    if torch.cuda.is_available() and processed_frames % (self.batch_size * 4) == 0:
                        torch.cuda.empty_cache()
            
            total_processing_time = time.time() - batch_start_time
            total_time = time.time() - start_total_time
            
            # 최종 결과 구성
            result = {
                'total_frames': actual_frame_count,
                'processed_frames': processed_frames,
                'jpeg_frames': jpeg_frames,
                'keypoints': keypoints_list,
                'scores': scores_list,
                'processing_time': total_processing_time,
                'total_time': total_time,
                'fps': actual_frame_count / max(total_processing_time, 0.001),
                'video_info': {
                    'original_fps': fps,
                    'resolution': f"{width}x{height}",
                    'duration': actual_frame_count / max(fps, 1.0)
                }
            }
            
            print(f"✅ 비디오 처리 완료:")
            print(f"   - 처리: {actual_frame_count}프레임 ({total_processing_time:.2f}초)")
            print(f"   - 속도: {result['fps']:.1f} FPS")
            print(f"   - 전체: {total_time:.2f}초")
            
            return result
            
        except Exception as e:
            print(f"💥 배치 비디오 처리 오류 ({video_path}): {e}")
            traceback.print_exc()
            return None
    
    def _process_frame_batch(self, frames: List[np.ndarray]) -> List[Optional[Tuple[List[List[int]], List[float], Optional[np.ndarray]]]]:
        """프레임 배치 처리 - Production Ready GPU 배치 추론 (크롭 이미지도 반환)"""
        results = []
        batch_start_time = time.time()
        
        try:
            if not frames:
                return []
            
            print(f"🔥 배치 프레임 처리: {len(frames)}개")
            
            # 각 프레임별 결과 초기화
            for _ in range(len(frames)):
                results.append(None)
            
            # GPU 배치 추론을 위한 준비
            all_crops = []  # 모든 크롭 이미지들
            all_crop_images = []  # 원본 크롭 이미지들 (JPEG 인코딩용)
            crop_frame_mapping = []  # 각 크롭이 어느 프레임에서 왔는지
            frame_person_counts = []  # 각 프레임에서 검출된 사람 수
            
            # 1단계: 모든 프레임에서 사람 검출 (YOLO)
            detection_start = time.time()
            for frame_idx, frame in enumerate(frames):
                try:
                    # YOLO 사람 검출 (고정확도)
                    person_boxes = self.inferencer.detect_persons_high_accuracy(frame)
                    person_count = len(person_boxes)
                    frame_person_counts.append(person_count)
                    
                    if person_count == 0:
                        continue
                    
                    # 각 사람 영역을 크롭하여 배치에 추가
                    for person_idx, bbox in enumerate(person_boxes):
                        try:
                            x1, y1, x2, y2 = map(int, bbox[:4])
                            x1, y1 = max(0, x1), max(0, y1)
                            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
                            
                            if x2 > x1 + 10 and y2 > y1 + 10:  # 최소 크기 체크
                                crop = frame[y1:y2, x1:x2]
                                
                                # 크롭 크기 확인
                                if crop.shape[0] > 0 and crop.shape[1] > 0:
                                    # RTMW 전처리 적용
                                    processed_crop = self.inferencer._preprocess_image_for_pose(crop)
                                    if processed_crop is not None:
                                        all_crops.append(processed_crop)
                                        all_crop_images.append(crop)  # 원본 크롭 이미지 저장
                                        crop_frame_mapping.append(frame_idx)
                                else:
                                    print(f"⚠️ 빈 크롭 이미지: frame {frame_idx}, person {person_idx}, bbox ({x1},{y1},{x2},{y2})")
                                    
                        except Exception as e:
                            print(f"⚠️ 프레임 {frame_idx} 사람 {person_idx} 크롭 실패: {e}")
                            continue
                    
                except Exception as e:
                    print(f"⚠️ 프레임 {frame_idx} YOLO 검출 실패: {e}")
                    frame_person_counts.append(0)
            
            detection_time = time.time() - detection_start
            print(f"   YOLO 검출: {len(all_crops)}개 사람 ({detection_time:.2f}초)")
            
            # 2단계: GPU 배치 포즈 추정 (ONNX)
            pose_start = time.time()
            batch_keypoints = []
            batch_scores = []
            
            if all_crops:
                # 배치 크기 조정 (GPU 메모리에 맞게)
                pose_batch_size = min(64, len(all_crops))  # A6000 기준 최적화
                
                for i in range(0, len(all_crops), pose_batch_size):
                    batch_slice = all_crops[i:i+pose_batch_size]
                    
                    try:
                        # ONNX 배치 추론
                        kpts_batch, scores_batch = self.inferencer.estimate_pose_batch(batch_slice)
                        
                        batch_keypoints.extend(kpts_batch)
                        batch_scores.extend(scores_batch)
                        
                    except Exception as e:
                        print(f"⚠️ 배치 포즈 추정 실패, 개별 처리로 폴백: {e}")
                        
                        # 폴백: 개별 처리
                        for crop in batch_slice:
                            try:
                                kpts, scores = self.inferencer.estimate_pose_on_crop(crop)
                                batch_keypoints.append(kpts)
                                batch_scores.append(scores)
                            except Exception as e2:
                                print(f"⚠️ 개별 포즈 추정도 실패: {e2}")
                                batch_keypoints.append(np.zeros((17, 2)))  # 기본값
                                batch_scores.append(np.zeros(17))
            
            pose_time = time.time() - pose_start
            print(f"   포즈 추정: {len(batch_keypoints)}개 결과 ({pose_time:.2f}초)")
            
            # 3단계: 결과를 프레임별로 재구성
            if batch_keypoints:
                crop_idx = 0
                
                for frame_idx in range(len(frames)):
                    person_count = frame_person_counts[frame_idx]
                    
                    if person_count == 0:
                        results[frame_idx] = ([], [], None)  # 빈 결과
                        continue
                    
                    frame_keypoints = []
                    frame_scores = []
                    first_crop_image = None  # 첫 번째 사람의 크롭 이미지 (streamlined 방식)
                    
                    # 해당 프레임의 모든 사람 결과 수집
                    for person_idx in range(person_count):
                        if crop_idx < len(batch_keypoints):
                            kpts = batch_keypoints[crop_idx]
                            scores = batch_scores[crop_idx]
                            
                            # 첫 번째 사람의 크롭 이미지 저장 (streamlined와 동일)
                            if person_idx == 0 and crop_idx < len(all_crop_images):
                                first_crop_image = all_crop_images[crop_idx]
                            
                            # 키포인트 형식 변환 (리스트로)
                            if isinstance(kpts, np.ndarray):
                                if kpts.ndim == 2:  # (17, 2) 형태
                                    kpts_flat = []
                                    for joint in kpts:
                                        kpts_flat.extend([float(joint[0]), float(joint[1])])
                                    frame_keypoints.append(kpts_flat)
                                else:
                                    frame_keypoints.append(kpts.flatten().tolist())
                            else:
                                frame_keypoints.append(kpts)
                            
                            if isinstance(scores, np.ndarray):
                                frame_scores.append(scores.tolist())
                            else:
                                frame_scores.append(scores)
                            
                            crop_idx += 1
                        else:
                            # 데이터 부족 시 기본값
                            frame_keypoints.append([0.0] * 34)  # 17 joints * 2 coords
                            frame_scores.append([0.0] * 17)
                    
                    results[frame_idx] = (frame_keypoints, frame_scores, first_crop_image)
            
            # 빈 결과들을 기본값으로 채움
            for i, result in enumerate(results):
                if result is None:
                    results[i] = ([[0.0] * 34], [[0.0] * 17], None)
            
            total_time = time.time() - batch_start_time
            print(f"✅ 배치 처리 완료: {len(frames)}프레임 ({total_time:.2f}초)")
            
            return results
            
        except Exception as e:
            print(f"💥 배치 처리 오류: {e}")
            traceback.print_exc()
            
            # 오류 시 빈 결과 반환
            return [([[0.0] * 34], [[0.0] * 17], None)] * len(frames)
    
    def _process_single_frame(self, frame: np.ndarray) -> Optional[Tuple[List[List[int]], List[float], Optional[np.ndarray]]]:
        """단일 프레임 처리 (폴백 용도) - 크롭 이미지도 반환"""
        try:
            # 추론 실행
            result = self.inferencer.process_frame(frame)
            
            # 결과 처리
            frame_keypoints = []
            frame_scores = []
            crop_image = None
            
            if isinstance(result, tuple) and len(result) > 1:
                _, pose_results = result
            else:
                pose_results = result if result is not None else []
            
            if pose_results and len(pose_results) > 0:
                for person in pose_results:
                    if isinstance(person, dict) and 'keypoints' in person:
                        kpts = person['keypoints']
                        if len(kpts) >= 34:  # 17 keypoints * 2
                            frame_keypoints.append(kpts[:34])
                            frame_scores.append(person.get('score', 1.0))
                
                # 첫 번째 사람의 크롭 이미지 생성 (streamlined 방식)
                try:
                    person_boxes = self.inferencer.detect_persons_high_accuracy(frame)
                    if len(person_boxes) > 0:
                        bbox = person_boxes[0]
                        x1, y1, x2, y2 = map(int, bbox[:4])
                        x1, y1 = max(0, x1), max(0, y1)
                        x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
                        
                        if x2 > x1 + 10 and y2 > y1 + 10:
                            crop_image = frame[y1:y2, x1:x2]
                except:
                    pass
            
            # 키포인트가 없는 경우 기본값
            if not frame_keypoints:
                frame_keypoints.append([0.0] * 34)
                frame_scores.append(0.0)
            
            return frame_keypoints, frame_scores, crop_image
            
        except Exception as e:
            print(f"⚠️ 단일 프레임 처리 오류: {e}")
            return ([[0.0] * 34], [0.0], None)

def batch_gpu_worker(
    gpu_id: int,
    task_queue: mp.Queue, 
    result_queue: mp.Queue, 
    progress_queue: mp.Queue,
    config: Dict
):
    """배치 GPU 워커 - 배치 256 최적화 + 진행률 추적"""
    try:
        # GPU 설정 - 강제로 특정 GPU만 보이도록 설정
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        
        # PyTorch CUDA 초기화
        torch.cuda.init()
        torch.cuda.set_device(0)  # 여기서는 0이 실제 gpu_id에 해당
        
        print(f"🚀 GPU {gpu_id} 워커 시작")
        print(f"   - CUDA 디바이스: {torch.cuda.current_device()}")
        print(f"   - GPU 이름: {torch.cuda.get_device_name(0)}")
        print(f"   - VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        
        # 배치 처리기 초기화
        processor = BatchFastVideoProcessor(
            rtmw_model_name=config['rtmw_model_name'],
            gpu_id=0,  # 워커에서는 항상 0 (CUDA_VISIBLE_DEVICES로 제어)
            batch_size=config['batch_size'],
            keypoint_scale=config.get('keypoint_scale', 8),
            jpeg_quality=config.get('jpeg_quality', 90),
            max_vram_usage=config.get('max_vram_usage', 0.85)
        )
        
        total_processed = 0
        worker_start_time = time.time()
        
        while True:
            try:
                # 작업 큐에서 가져오기 (타임아웃 설정)
                try:
                    task = task_queue.get(timeout=5.0)
                    if task is None:  # 종료 신호
                        break
                except queue.Empty:
                    continue
                
                video_path, task_id = task
                
                # 진행률 추적을 위한 콜백
                def progress_callback(progress):
                    try:
                        progress_queue.put({
                            'task_id': task_id,
                            'gpu_id': gpu_id,
                            'progress': progress,
                            'status': 'processing'
                        })
                    except Exception as e:
                        print(f"⚠️ 진행률 업데이트 실패: {e}")
                
                print(f"🔥 GPU {gpu_id} 처리 시작: {Path(video_path).name}")
                start_time = time.time()
                
                # 비디오 처리
                result = processor.process_video_batch_optimized(video_path, progress_callback)
                
                processing_time = time.time() - start_time
                
                if result:
                    fps_achieved = result.get('fps', 0)
                    frame_count = result.get('total_frames', 0)
                    
                    print(f"✅ GPU {gpu_id} 완료: {frame_count}프레임, {fps_achieved:.1f}FPS ({processing_time:.2f}초)")
                    
                    # 결과 큐에 저장
                    result_item = {
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'video_path': video_path,
                        'result': result,
                        'processing_time': processing_time,
                        'fps_achieved': fps_achieved,
                        'frame_count': frame_count,
                        'status': 'completed'
                    }
                    
                else:
                    print(f"❌ GPU {gpu_id} 처리 실패: {Path(video_path).name}")
                    result_item = {
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'video_path': video_path,
                        'result': None,
                        'processing_time': processing_time,
                        'status': 'failed'
                    }
                
                # 결과 전송
                result_queue.put(result_item)
                total_processed += 1
                
                # 진행률 완료 신호
                try:
                    progress_queue.put({
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'progress': 1.0,
                        'status': 'completed'
                    })
                except Exception as e:
                    print(f"⚠️ 완료 신호 전송 실패: {e}")
                
                # 메모리 정리
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"💥 GPU {gpu_id} 작업 오류: {e}")
                traceback.print_exc()
                
                # 오류 결과 전송
                try:
                    result_queue.put({
                        'task_id': task_id if 'task_id' in locals() else -1,
                        'gpu_id': gpu_id,
                        'video_path': video_path if 'video_path' in locals() else 'unknown',
                        'result': None,
                        'status': 'error',
                        'error': str(e)
                    })
                except:
                    pass
        
        worker_time = time.time() - worker_start_time
        print(f"🏁 GPU {gpu_id} 워커 종료: {total_processed}개 처리 ({worker_time:.2f}초)")
        
    except Exception as e:
        print(f"💥 GPU {gpu_id} 워커 초기화 실패: {e}")
        traceback.print_exc()

def process_videos_dual_gpu_async_batch(
    video_paths: List[str],
    output_dir: str,
    config: Dict,
    progress_callback=None
) -> Dict:
    """듀얼 GPU 완전 비동기 배치 256 처리 - 확실한 병렬 처리"""
    
    start_time = time.time()
    total_videos = len(video_paths)
    
    print(f"🚀 듀얼 GPU 완전 비동기 배치 256 처리 시작")
    print(f"   - 총 비디오: {total_videos}개")
    print(f"   - 출력 디렉토리: {output_dir}")
    print(f"   - 배치 크기: {config['batch_size']}")
    print(f"   - GPU 병렬 모드: 완전 비동기 (0번, 1번 동시 처리)")
    
    # 출력 디렉토리 생성
    os.makedirs(output_dir, exist_ok=True)
    
    # 멀티프로세싱 설정 (확실한 분리를 위해 spawn)
    mp.set_start_method('spawn', force=True)
    
    # 각 GPU별로 독립적인 큐와 프로세스 생성
    gpu_configs = []
    for gpu_id in range(2):
        gpu_config = {
            'task_queue': mp.Queue(),
            'result_queue': mp.Queue(), 
            'progress_queue': mp.Queue(),
            'process': None,
            'gpu_id': gpu_id,
            'tasks_assigned': 0
        }
        gpu_configs.append(gpu_config)
    
    # 비디오를 두 GPU에 라운드로빈 방식으로 균등 분배
    for idx, video_path in enumerate(video_paths):
        gpu_id = idx % 2  # 0, 1, 0, 1, 0, 1...
        gpu_configs[gpu_id]['task_queue'].put((video_path, idx))
        gpu_configs[gpu_id]['tasks_assigned'] += 1
    
    # 각 GPU에 종료 신호 추가
    for gpu_config in gpu_configs:
        gpu_config['task_queue'].put(None)
    
    print(f"📊 작업 분배:")
    for gpu_config in gpu_configs:
        print(f"   - GPU {gpu_config['gpu_id']}: {gpu_config['tasks_assigned']}개 비디오")
    
    # 각 GPU별로 독립적인 워커 프로세스 시작
    for gpu_config in gpu_configs:
        worker = mp.Process(
            target=async_batch_gpu_worker,
            args=(
                gpu_config['gpu_id'],
                gpu_config['task_queue'],
                gpu_config['result_queue'],
                gpu_config['progress_queue'],
                config
            )
        )
        worker.start()
        gpu_config['process'] = worker
        print(f"🚀 GPU {gpu_config['gpu_id']} 워커 시작 (PID: {worker.pid})")
    
    # 결과 수집을 위한 통합 처리
    results = {}
    completed_count = 0
    failed_count = 0
    
    print(f"⏳ 비동기 처리 진행 중...")
    
    # 진행률 추적을 위한 비동기 모니터링
    def async_progress_monitor():
        """비동기 진행률 모니터 - 간소화"""
        last_update = time.time()
        
        while completed_count + failed_count < total_videos:
            try:
                # 주기적으로 전체 진행률 업데이트
                current_time = time.time()
                if current_time - last_update > 3.0:  # 3초마다 업데이트
                    total_progress = (completed_count + failed_count) / total_videos
                    
                    if progress_callback:
                        progress_callback(min(total_progress, 1.0))
                    
                    # 간단한 진행률 출력
                    print(f"📊 진행률: {completed_count + failed_count}/{total_videos} ({total_progress:.1%}) - GPU별 작업 진행 중...")
                    
                    last_update = current_time
                
                time.sleep(1.0)  # 1초마다 체크
                
            except Exception as e:
                print(f"⚠️ 비동기 진행률 모니터 오류: {e}")
                break
    
    # 진행률 모니터 스레드 시작
    monitor_thread = threading.Thread(target=async_progress_monitor, daemon=True)
    monitor_thread.start()
    
    # 각 GPU의 결과를 비동기적으로 수집
    def collect_results_from_gpu(gpu_config):
        """특정 GPU로부터 결과 수집"""
        gpu_completed = 0
        gpu_failed = 0
        
        while gpu_completed + gpu_failed < gpu_config['tasks_assigned']:
            try:
                result_item = gpu_config['result_queue'].get(timeout=30.0)  # 타임아웃을 30초로 증가
                
                task_id = result_item['task_id']
                status = result_item['status']
                
                results[task_id] = result_item
                
                if status == 'completed':
                    gpu_completed += 1
                    
                    # Streamlined HDF5 파일로 저장
                    video_path = result_item['video_path']
                    result_data = result_item['result']
                    
                    if result_data:
                        output_filename = Path(video_path).stem + '.h5'
                        output_path = os.path.join(output_dir, output_filename)
                        
                        try:
                            video_id = Path(video_path).stem.replace('NIA_SL_', '').split('_')[0]
                            save_to_hdf5_streamlined_format(result_data, output_path, video_id)
                            print(f"💾 GPU {gpu_config['gpu_id']} 저장 완료: {video_id}")
                        except Exception as e:
                            print(f"⚠️ GPU {gpu_config['gpu_id']} 저장 실패 ({Path(video_path).name}): {e}")
                    
                else:
                    gpu_failed += 1
                    print(f"❌ GPU {gpu_config['gpu_id']} 처리 실패: {Path(result_item.get('video_path', 'unknown')).name}")
                
            except queue.Empty:
                print(f"⚠️ GPU {gpu_config['gpu_id']} 결과 대기 타임아웃")
                break
            except Exception as e:
                print(f"� GPU {gpu_config['gpu_id']} 결과 수집 오류: {e}")
                break
        
        return gpu_completed, gpu_failed
    
    # 각 GPU별로 별도 스레드에서 결과 수집
    result_threads = []
    gpu_results = {}
    
    for gpu_config in gpu_configs:
        def make_collector(config):
            def collector():
                gpu_results[config['gpu_id']] = collect_results_from_gpu(config)
            return collector
        
        thread = threading.Thread(target=make_collector(gpu_config), daemon=False)
        thread.start()
        result_threads.append(thread)
    
    # 모든 결과 수집 스레드 완료 대기
    for thread in result_threads:
        thread.join()
    
    # 결과 집계
    for gpu_id, (gpu_completed, gpu_failed) in gpu_results.items():
        completed_count += gpu_completed
        failed_count += gpu_failed
        print(f"� GPU {gpu_id} 완료: 성공 {gpu_completed}개, 실패 {gpu_failed}개")
    
    # 워커 프로세스 종료 대기
    for gpu_config in gpu_configs:
        worker = gpu_config['process']
        worker.join(timeout=10.0)
        if worker.is_alive():
            print(f"⚠️ GPU {gpu_config['gpu_id']} 워커 강제 종료")
            worker.terminate()
    
    total_time = time.time() - start_time
    
    # 최종 결과 정리
    summary = {
        'total_videos': total_videos,
        'completed': completed_count,
        'failed': failed_count,
        'total_time': total_time,
        'average_time_per_video': total_time / max(total_videos, 1),
        'gpu_distribution': {gpu_config['gpu_id']: gpu_config['tasks_assigned'] for gpu_config in gpu_configs},
        'results': results
    }
    
    print(f"🏁 듀얼 GPU 완전 비동기 처리 완료:")
    print(f"   - 성공: {completed_count}개")
    print(f"   - 실패: {failed_count}개")
    print(f"   - 총 시간: {total_time:.2f}초")
    print(f"   - 평균 시간: {summary['average_time_per_video']:.2f}초/비디오")
    print(f"   - GPU별 처리량: {summary['gpu_distribution']}")
    
    return summary

def async_batch_gpu_worker(
    gpu_id: int,
    task_queue: mp.Queue, 
    result_queue: mp.Queue, 
    progress_queue: mp.Queue,
    config: Dict
):
    """완전 비동기 배치 GPU 워커 - GPU별 독립적 처리"""
    try:
        # GPU 설정 - 확실한 GPU 분리
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        
        # PyTorch CUDA 초기화
        import torch
        torch.cuda.init()
        torch.cuda.set_device(0)  # CUDA_VISIBLE_DEVICES로 제어되므로 0이 실제 gpu_id
        
        print(f"🚀 비동기 GPU {gpu_id} 워커 시작")
        print(f"   - CUDA 디바이스: {torch.cuda.current_device()}")
        print(f"   - GPU 이름: {torch.cuda.get_device_name(0)}")
        print(f"   - VRAM 총량: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        
        # GPU별로 독립적인 배치 처리기 초기화
        processor = BatchFastVideoProcessor(
            rtmw_model_name=config['rtmw_model_name'],
            gpu_id=0,  # 워커에서는 항상 0 (CUDA_VISIBLE_DEVICES로 제어)
            batch_size=config['batch_size'],
            keypoint_scale=config.get('keypoint_scale', 8),
            jpeg_quality=config.get('jpeg_quality', 90),
            max_vram_usage=config.get('max_vram_usage', 0.8)  # 비동기 처리시 여유 확보
        )
        
        total_processed = 0
        worker_start_time = time.time()
        
        while True:
            try:
                # 작업 큐에서 가져오기
                try:
                    task = task_queue.get(timeout=5.0)
                    if task is None:  # 종료 신호
                        print(f"🔚 GPU {gpu_id} 워커 종료 신호 받음")
                        break
                except queue.Empty:
                    continue
                
                video_path, task_id = task
                print(f"🔥 GPU {gpu_id} 작업 시작: {Path(video_path).name} (Task {task_id})")
                
                # 진행률 콜백 정의 - 올바른 들여쓰기
                def progress_callback(progress):
                    try:
                        progress_queue.put_nowait({
                            'task_id': task_id,
                            'gpu_id': gpu_id,
                            'progress': progress,
                            'status': 'processing',
                            'timestamp': time.time()
                        })
                    except queue.Full:
                        pass  # 진행률 큐가 가득 차면 무시
                
                # 비디오 처리 실행
                task_start_time = time.time()
                result = processor.process_video_batch_optimized(video_path, progress_callback)
                processing_time = time.time() - task_start_time
                
                # 결과 처리
                if result:
                    fps_achieved = result.get('fps', 0)
                    frame_count = result.get('total_frames', 0)
                    
                    print(f"✅ GPU {gpu_id} 완료: {Path(video_path).name} - {frame_count}프레임, {fps_achieved:.1f}FPS ({processing_time:.2f}초)")
                    
                    result_item = {
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'video_path': video_path,
                        'result': result,
                        'processing_time': processing_time,
                        'fps_achieved': fps_achieved,
                        'frame_count': frame_count,
                        'status': 'completed',
                        'timestamp': time.time()
                    }
                else:
                    print(f"❌ GPU {gpu_id} 실패: {Path(video_path).name}")
                    result_item = {
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'video_path': video_path,
                        'result': None,
                        'processing_time': processing_time,
                        'status': 'failed',
                        'timestamp': time.time()
                    }
                
                # 결과 전송
                result_queue.put(result_item)
                total_processed += 1
                
                print(f"📤 GPU {gpu_id} 결과 전송 완료: Task {task_id}")
                
                # 완료 진행률 신호
                try:
                    progress_queue.put_nowait({
                        'task_id': task_id,
                        'gpu_id': gpu_id,
                        'progress': 1.0,
                        'status': 'completed',
                        'timestamp': time.time()
                    })
                except queue.Full:
                    pass
                
                # 주기적 GPU 메모리 정리
                if total_processed % 3 == 0:
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"💥 GPU {gpu_id} 작업 오류: {e}")
                traceback.print_exc()
                
                # 오류 결과 전송
                try:
                    error_result = {
                        'task_id': task_id if 'task_id' in locals() else -1,
                        'gpu_id': gpu_id,
                        'video_path': video_path if 'video_path' in locals() else 'unknown',
                        'result': None,
                        'processing_time': 0.0,
                        'status': 'error',
                        'error': str(e),
                        'timestamp': time.time()
                    }
                    result_queue.put(error_result)
                    total_processed += 1
                except:
                    pass
        
        worker_time = time.time() - worker_start_time
        print(f"🏁 GPU {gpu_id} 워커 종료: {total_processed}개 처리 ({worker_time:.2f}초)")
        
    except Exception as e:
        print(f"💥 GPU {gpu_id} 워커 초기화 실패: {e}")
        traceback.print_exc()

def save_to_hdf5_streamlined_format(result_data: Dict, output_path: str, video_id: str):
    """Streamlined 방식으로 HDF5 저장 - 프레임과 포즈 분리 (완벽 호환)"""
    try:
        output_path_obj = Path(output_path)
        
        # 프레임과 포즈 파일 분리 (streamlined 형식)
        frames_h5_path = output_path_obj.parent / f"{output_path_obj.stem}_frames.h5"
        poses_h5_path = output_path_obj.parent / f"{output_path_obj.stem}_poses.h5"
        
        # JPEG 가변 길이 타입 (streamlined와 동일)
        jpeg_vlen_dtype = h5py.vlen_dtype(np.uint8)
        
        with h5py.File(frames_h5_path, 'w') as f_frames, \
             h5py.File(poses_h5_path, 'w') as f_poses:
            
            # 배치 메타데이터 (streamlined와 동일한 구조)
            batch_metadata = {
                'folder_name': 'batch_processing',
                'folder_batch_idx': 0,
                'item_range': video_id,
                'item_types': ['WORD'],
                'direction': 'F',
                'video_count': 1,
                'creation_time': str(datetime.now())
            }
            f_frames.attrs.update(batch_metadata)
            f_poses.attrs.update(batch_metadata)
            
            # streamlined와 동일한 그룹 이름 형식
            video_group_name = f"video_{video_id.lower()}"
            
            # === 프레임 파일 저장 (streamlined 방식) ===
            frame_group = f_frames.create_group(video_group_name)
            
            # JPEG 프레임 데이터 처리 (streamlined와 완전 동일)
            jpeg_frames = result_data.get('jpeg_frames', [])
            if jpeg_frames:
                # streamlined와 동일: cv2.imencode 결과인 numpy 배열 직접 저장
                frame_group.create_dataset("frames_jpeg", data=jpeg_frames, dtype=jpeg_vlen_dtype)
            
            # 메타데이터 저장 (streamlined와 완전 동일한 형식)
            metadata = {
                'item_type': 'WORD',
                'item_id': int(video_id.replace('WORD', '').replace('word', '')) if 'word' in video_id.lower() else 0,
                'video_path': result_data.get('video_path', ''),
                'video_filename': Path(result_data.get('video_path', '')).name,
                'frame_count': result_data['total_frames'],
                'processing_time': result_data.get('processing_time', 0.0),
                'keypoint_scale': 8,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            f_frames.create_dataset(f"{video_group_name}/metadata", data=json.dumps(metadata))
            
            # === 포즈 파일 저장 (streamlined 방식) ===
            pose_group = f_poses.create_group(video_group_name)
            
            # 키포인트 데이터 변환 (streamlined와 완전 동일)
            keypoints = result_data.get('keypoints', [])
            scores = result_data.get('scores', [])
            
            if keypoints and scores:
                # streamlined와 동일한 데이터 처리
                num_frames = len(keypoints)
                
                # RTMW 133개 키포인트 배열 초기화
                keypoints_array = np.zeros((num_frames, 133, 2), dtype=np.float32)
                scores_array = np.zeros((num_frames, 133), dtype=np.float32)
                
                for frame_idx, (frame_kpts, frame_scores) in enumerate(zip(keypoints, scores)):
                    # 첫 번째 사람만 사용 (streamlined와 동일)
                    if isinstance(frame_kpts, list) and len(frame_kpts) > 0:
                        person_kpts = frame_kpts[0]
                        person_scores = frame_scores[0] if len(frame_scores) > 0 else []
                        
                        # 키포인트 변환 (x,y,x,y... -> [[x,y], [x,y], ...])
                        if isinstance(person_kpts, list) and len(person_kpts) >= 266:  # 133*2
                            for joint_idx in range(133):
                                x_idx = joint_idx * 2
                                y_idx = joint_idx * 2 + 1
                                if y_idx < len(person_kpts):
                                    keypoints_array[frame_idx, joint_idx, 0] = person_kpts[x_idx]
                                    keypoints_array[frame_idx, joint_idx, 1] = person_kpts[y_idx]
                        
                        # 스코어 변환 (streamlined와 동일)
                        if isinstance(person_scores, list) and len(person_scores) >= 133:
                            scores_array[frame_idx, :] = person_scores[:133]
                
                # 키포인트 8배 스케일링 후 int32로 저장 (streamlined와 완전 동일)
                keypoints_scaled = np.round(keypoints_array * 8).astype(np.int32)
                
                # streamlined와 동일한 데이터셋 이름과 압축
                pose_group.create_dataset("keypoints_scaled", data=keypoints_scaled, compression='lzf')
                pose_group.create_dataset("scores", data=scores_array, compression='lzf')
        
        print(f"✅ Streamlined HDF5 저장 완료: {frames_h5_path.name}, {poses_h5_path.name}")
        
    except Exception as e:
        print(f"💥 Streamlined HDF5 저장 실패 ({video_id}): {e}")
        traceback.print_exc()
        raise


# ===== 메인 실행 함수 =====

def find_test_videos(data_root: str = "data/1.Training/videos") -> List[str]:
    """테스트용 비디오 파일 찾기"""
    video_paths = []
    
    # 데이터 루트 경로 설정
    if not os.path.exists(data_root):
        data_root = "/workspace01/team03/data/mmpose/jy/data/1.Training/videos"
    
    if not os.path.exists(data_root):
        print(f"❌ 비디오 디렉토리를 찾을 수 없습니다: {data_root}")
        return []
    
    print(f"🔍 비디오 파일 탐색: {data_root}")
    
    # .mp4 파일 찾기
    for root, dirs, files in os.walk(data_root):
        for file in files:
            if file.endswith(('.mp4', '.avi', '.mov')) and 'F.mp4' in file:
                file_path = os.path.join(root, file)
                video_paths.append(file_path)
    
    # 처리 가능한 개수로 제한 (테스트용)
    video_paths = sorted(video_paths)[:10]  # 최대 10개로 제한
    
    print(f"✅ 발견된 비디오: {len(video_paths)}개")
    for i, path in enumerate(video_paths[:5]):  # 처음 5개만 표시
        file_size = os.path.getsize(path) / (1024*1024)  # MB
        print(f"   {i+1}. {os.path.basename(path)} ({file_size:.1f}MB)")
    
    if len(video_paths) > 5:
        print(f"   ... 및 {len(video_paths) - 5}개 추가 파일")
    
    return video_paths


def main():
    """듀얼 GPU 배치 256 처리기 메인 실행 함수 - 테스트 또는 전체 폴더 처리"""
    import argparse
    import sys
    
    # 명령줄 인자 파싱 (선택적)
    parser = argparse.ArgumentParser(description="Batch Fast Multi-ONNX Processor", add_help=False)
    parser.add_argument("--input_folder", type=str, 
                        help="전체 폴더 처리시 입력 폴더 경로")
    parser.add_argument("--output_folder", type=str,
                        help="전체 폴더 처리시 출력 폴더 경로") 
    parser.add_argument("--batch_size", type=int, default=250,
                        help="배치 크기 (기본값: 250)")
    parser.add_argument("--test", action="store_true",
                        help="테스트 모드 (10개 비디오만 처리)")
    parser.add_argument("--help", "-h", action="store_true",
                        help="도움말 표시")
    
    # 인자가 있는 경우에만 파싱
    args = None
    if len(sys.argv) > 1:
        try:
            args = parser.parse_args()
        except SystemExit:
            pass
    
    if args and args.help:
        print("🚀 Batch Fast Multi-ONNX Processor")
        print("=" * 60)
        print("사용법:")
        print("  1. 테스트 모드 (10개 비디오):")
        print("     python batch_fast_multionnx_processor.py")
        print("     python batch_fast_multionnx_processor.py --test")
        print()
        print("  2. 전체 폴더 처리 (250개씩 배치):")
        print("     python batch_fast_multionnx_processor.py \\")
        print("       --input_folder /path/to/videos \\")
        print("       --output_folder /path/to/output \\")
        print("       --batch_size 250")
        print()
        print("옵션:")
        print("  --input_folder   입력 비디오 폴더 경로")
        print("  --output_folder  출력 HDF5 폴더 경로")
        print("  --batch_size     배치 크기 (기본값: 250)")
        print("  --test          테스트 모드 (10개만 처리)")
        print("  --help, -h      이 도움말 표시")
        return 0
    
    print("🚀 Batch Fast Multi-ONNX Processor 시작")
    print("=" * 60)
    
    # 전체 폴더 처리 모드인지 확인
    if args and args.input_folder and args.output_folder:
        print("📂 전체 폴더 처리 모드")
        print(f"   - 입력 폴더: {args.input_folder}")
        print(f"   - 출력 폴더: {args.output_folder}")
        print(f"   - 배치 크기: {args.batch_size}개씩 처리")
        print(f"   - Streamlined 네이밍: batch_XX_F_frames.h5, batch_XX_F_poses.h5")
        
        try:
            result = process_full_folder_production(
                input_folder=args.input_folder,
                output_folder=args.output_folder,
                batch_size=args.batch_size,
                processing_batch_size=128,
                max_vram_usage=0.75
            )
            
            if result['status'] == 'completed':
                print("\n🎉 전체 폴더 처리 성공!")
                return 0
            else:
                print(f"\n❌ 전체 폴더 처리 실패: {result.get('reason', 'unknown')}")
                return 1
                
        except Exception as e:
            print(f"\n💥 전체 폴더 처리 오류: {e}")
            traceback.print_exc()
            return 1
    
    else:
        # 테스트 모드
        print("🧪 테스트 모드 (10개 비디오 처리)")
        
        # 설정
        config = {
            'rtmw_model_name': 'rtmw-dw-x-l_simcc-cocktail14_270e-384x288.onnx',
            'batch_size': 128,  # 안정성을 위해 128로 설정
            'keypoint_scale': 8,
            'jpeg_quality': 90,
            'max_vram_usage': 0.75
        }
        
        # 출력 디렉토리 설정
        output_dir = "/tmp/batch_fast_multionnx_test_output"
        
        # 테스트 비디오 찾기
        video_paths = find_test_videos()
        
        if not video_paths:
            print("❌ 처리할 비디오 파일이 없습니다.")
            print("💡 다음 위치에 비디오 파일을 확인하세요:")
            print("   - data/1.Training/videos")
            print("   - /workspace01/team03/data/mmpose/jy/data/1.Training/videos")
            print()
            print("💡 전체 폴더 처리를 원하시면:")
            print("   python batch_fast_multionnx_processor.py \\")
            print("     --input_folder /path/to/videos \\")
            print("     --output_folder /path/to/output")
            return 1
        
        print(f"\n⚙️ 처리 설정:")
        print(f"   - 배치 크기: {config['batch_size']}")
        print(f"   - RTMW 모델: {config['rtmw_model_name']}")
        print(f"   - VRAM 사용률: {config['max_vram_usage']*100}%")
        print(f"   - 출력 디렉토리: {output_dir}")
        
        # GPU 확인
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                print(f"\n🖥️ GPU 정보:")
                for i in range(min(gpu_count, 2)):  # 최대 2개 GPU만 표시
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    print(f"   - GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                print("⚠️ CUDA GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.")
        except ImportError:
            print("⚠️ PyTorch를 찾을 수 없습니다.")
        
        print(f"\n🔥 듀얼 GPU 처리 시작...")
        print(f"   - 총 비디오: {len(video_paths)}개")
        print(f"   - GPU 0번과 1번이 동시에 처리됩니다")
        print(f"   - 각 GPU는 독립적으로 작업을 수행합니다")
        
        # 진행률 콜백 함수
        def progress_callback(progress):
            if hasattr(progress_callback, 'last_progress'):
                if progress - progress_callback.last_progress >= 0.1:  # 10%씩 업데이트
                    print(f"📊 전체 진행률: {progress*100:.1f}%")
                    progress_callback.last_progress = progress
            else:
                progress_callback.last_progress = 0.0
        
        try:
            # 듀얼 GPU 비동기 처리 실행
            start_time = time.time()
            
            summary = process_videos_dual_gpu_async_batch(
                video_paths=video_paths,
                output_dir=output_dir,
                config=config,
                progress_callback=progress_callback
            )
            
            total_time = time.time() - start_time
            
            # 결과 분석
            print(f"\n🏁 처리 결과 분석")
            print("=" * 60)
            print(f"✅ 처리 완료:")
            print(f"   - 성공: {summary['completed']}개")
            print(f"   - 실패: {summary['failed']}개")
            print(f"   - 총 시간: {total_time:.2f}초")
            print(f"   - 평균 시간: {summary['average_time_per_video']:.2f}초/비디오")
            
            if summary['completed'] > 0:
                print(f"\n🖥️ GPU 병렬 처리 확인:")
                gpu_dist = summary['gpu_distribution']
                for gpu_id, task_count in gpu_dist.items():
                    print(f"   - GPU {gpu_id}: {task_count}개 작업 처리")
                
                # 작업 분배 균형도 계산
                if len(gpu_dist) > 1:
                    task_counts = list(gpu_dist.values())
                    balance = min(task_counts) / max(task_counts) * 100 if max(task_counts) > 0 else 0
                    print(f"   - 작업 균형도: {balance:.1f}%")
                    
                    if balance > 80:
                        print("   ✅ GPU 작업 분배가 균등합니다")
                    else:
                        print("   ⚠️ GPU 작업 분배가 불균등합니다")
            
            # 저장된 파일 확인
            if os.path.exists(output_dir):
                h5_files = [f for f in os.listdir(output_dir) if f.endswith('.h5')]
                frames_files = [f for f in h5_files if 'frames' in f]
                poses_files = [f for f in h5_files if 'poses' in f]
                
                print(f"\n💾 저장된 HDF5 파일:")
                print(f"   - 프레임 파일: {len(frames_files)}개")
                print(f"   - 포즈 파일: {len(poses_files)}개")
                
                # 파일 크기 정보 (처음 3개만)
                for f in frames_files[:3]:
                    file_path = os.path.join(output_dir, f)
                    file_size = os.path.getsize(file_path) / (1024*1024)  # MB
                    print(f"     📄 {f} ({file_size:.1f}MB)")
            
            # 성능 지표 계산
            if summary['completed'] > 0:
                total_videos = summary['completed']
                avg_fps = 0
                
                for result_data in summary['results'].values():
                    if result_data.get('status') == 'completed' and result_data.get('result'):
                        fps = result_data['result'].get('fps', 0)
                        avg_fps += fps
                
                if total_videos > 0:
                    avg_fps /= total_videos
                    print(f"\n⚡ 성능 지표:")
                    print(f"   - 평균 FPS: {avg_fps:.1f}")
                    print(f"   - 총 처리 시간: {total_time:.2f}초")
                    
                    if avg_fps > 10:
                        print("   ✅ 우수한 처리 성능")
                    elif avg_fps > 5:
                        print("   ✅ 양호한 처리 성능")
                    else:
                        print("   ⚠️ 성능 최적화 필요")
            
            # GPU 병렬 처리 검증
            gpu_used = len([gpu_id for gpu_id, count in summary['gpu_distribution'].items() if count > 0])
            print(f"\n🔍 GPU 병렬 처리 검증:")
            if gpu_used > 1:
                print(f"   ✅ {gpu_used}개 GPU가 모두 작업을 처리했습니다")
                print("   ✅ 듀얼 GPU 병렬 처리가 성공적으로 작동합니다")
            else:
                print("   ⚠️ 단일 GPU만 사용되었습니다")
            
            # Streamlined HDF5 형식 검증
            if frames_files and poses_files:
                print(f"\n📋 Streamlined HDF5 형식 검증:")
                print("   ✅ 프레임과 포즈 파일이 분리되어 저장되었습니다")
                print("   ✅ Streamlined 호환 형식으로 저장 완료")
            
            print(f"\n🎉 테스트 처리 성공!")
            print(f"   - 모든 비디오 처리 완료")
            print(f"   - GPU 병렬 처리 확인")  
            print(f"   - Streamlined HDF5 저장 완료")
            
            # 전체 폴더 처리 안내
            print(f"\n💡 전체 폴더 처리를 원하시면:")
            print(f"   python {sys.argv[0]} \\")
            print(f"     --input_folder /path/to/videos \\") 
            print(f"     --output_folder /path/to/output \\")
            print(f"     --batch_size 250")
            
        except KeyboardInterrupt:
            print("\n\n⏹️  사용자에 의해 중단되었습니다")
            return 1
        except Exception as e:
            print(f"\n💥 처리 중 오류 발생: {e}")
            traceback.print_exc()
            return 1
    
    print("=" * 60)
    print("처리 완료")
    return 0


# ===== Production 전체 폴더 처리 함수들 =====

def find_all_videos_in_folder(folder_path: str) -> List[str]:
    """폴더에서 모든 비디오 파일 찾기"""
    video_paths = []
    
    if not os.path.exists(folder_path):
        print(f"❌ 폴더가 존재하지 않습니다: {folder_path}")
        return []
    
    print(f"🔍 비디오 파일 탐색: {folder_path}")
    
    # 지원되는 비디오 확장자
    video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            file_lower = file.lower()
            file_ext = Path(file).suffix.lower()
            
            # 비디오 파일이고 '_F.mp4' 패턴을 포함하는 경우
            if file_ext in video_extensions and '_F.mp4' in file:
                file_path = os.path.join(root, file)
                video_paths.append(file_path)
    
    # 정렬
    video_paths = sorted(video_paths)
    
    print(f"✅ 발견된 비디오: {len(video_paths)}개")
    return video_paths

def create_batches(video_paths: List[str], batch_size: int = 250) -> List[List[str]]:
    """비디오 리스트를 배치로 나누기"""
    batches = []
    
    for i in range(0, len(video_paths), batch_size):
        batch = video_paths[i:i + batch_size]
        batches.append(batch)
    
    print(f"📦 배치 생성: {len(batches)}개 배치 (배치당 최대 {batch_size}개)")
    for i, batch in enumerate(batches):
        print(f"   - 배치 {i:02d}: {len(batch)}개 비디오")
    
    return batches

def get_streamlined_naming(batch_idx: int, data_type: str) -> str:
    """Streamlined 네이밍 규칙에 따른 파일명 생성
    
    Args:
        batch_idx: 배치 인덱스 (0부터 시작)
        data_type: 'frames' 또는 'poses'
    
    Returns:
        파일명 (예: batch_00_F_frames.h5, batch_01_F_poses.h5)
    """
    return f"batch_{batch_idx:02d}_F_{data_type}.h5"

def save_batch_to_streamlined_hdf5(batch_results: List[Dict], batch_idx: int, output_dir: str):
    """배치 결과를 Streamlined HDF5 형식으로 저장 (250개씩)"""
    try:
        # Streamlined 네이밍 규칙 적용
        frames_filename = get_streamlined_naming(batch_idx, 'frames')
        poses_filename = get_streamlined_naming(batch_idx, 'poses')
        
        frames_h5_path = os.path.join(output_dir, frames_filename)
        poses_h5_path = os.path.join(output_dir, poses_filename)
        
        print(f"💾 배치 {batch_idx:02d} HDF5 저장 시작:")
        print(f"   - 프레임: {frames_filename}")
        print(f"   - 포즈: {poses_filename}")
        print(f"   - 비디오 수: {len(batch_results)}개")
        
        # JPEG 가변 길이 타입
        jpeg_vlen_dtype = h5py.vlen_dtype(np.uint8)
        
        with h5py.File(frames_h5_path, 'w') as f_frames, \
             h5py.File(poses_h5_path, 'w') as f_poses:
            
            # 배치 메타데이터
            batch_metadata = {
                'folder_name': f'batch_{batch_idx:02d}',
                'folder_batch_idx': batch_idx,
                'item_range': f'batch_{batch_idx:02d}',
                'item_types': ['WORD'],
                'direction': 'F',
                'video_count': len(batch_results),
                'creation_time': str(datetime.now()),
                'processing_version': 'batch_fast_multionnx_v1.0'
            }
            f_frames.attrs.update(batch_metadata)
            f_poses.attrs.update(batch_metadata)
            
            # 각 비디오 결과 처리
            for video_idx, result_item in enumerate(batch_results):
                video_path = result_item['video_path']
                result_data = result_item['result']
                
                if not result_data:
                    print(f"⚠️ 빈 결과 스킵: {Path(video_path).name}")
                    continue
                
                # 비디오 ID 추출 (NIA_SL_WORD_01_01_F.mp4 -> word_01_01)
                video_filename = Path(video_path).stem
                try:
                    if 'WORD' in video_filename.upper():
                        # NIA_SL_WORD_01_01_F -> word_01_01
                        parts = video_filename.split('_')
                        word_part_idx = None
                        for i, part in enumerate(parts):
                            if 'WORD' in part.upper():
                                word_part_idx = i
                                break
                        
                        if word_part_idx is not None and len(parts) > word_part_idx + 2:
                            video_id = f"word_{parts[word_part_idx + 1]}_{parts[word_part_idx + 2]}"
                        else:
                            video_id = f"video_{batch_idx:02d}_{video_idx:03d}"
                    else:
                        video_id = f"video_{batch_idx:02d}_{video_idx:03d}"
                except:
                    video_id = f"video_{batch_idx:02d}_{video_idx:03d}"
                
                video_group_name = f"video_{video_id.lower()}"
                
                print(f"   📹 처리 중: {video_filename} -> {video_group_name}")
                
                # === 프레임 파일 저장 ===
                frame_group = f_frames.create_group(video_group_name)
                
                jpeg_frames = result_data.get('jpeg_frames', [])
                if jpeg_frames:
                    frame_group.create_dataset("frames_jpeg", data=jpeg_frames, dtype=jpeg_vlen_dtype)
                
                # 프레임 메타데이터
                frame_metadata = {
                    'item_type': 'WORD',
                    'item_id': video_idx,
                    'video_path': video_path,
                    'video_filename': Path(video_path).name,
                    'frame_count': result_data.get('total_frames', 0),
                    'processing_time': result_data.get('processing_time', 0.0),
                    'keypoint_scale': 8,
                    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'gpu_id': result_item.get('gpu_id', -1),
                    'fps_achieved': result_item.get('fps_achieved', 0.0)
                }
                frame_group.create_dataset("metadata", data=json.dumps(frame_metadata))
                
                # === 포즈 파일 저장 ===
                pose_group = f_poses.create_group(video_group_name)
                
                keypoints = result_data.get('keypoints', [])
                scores = result_data.get('scores', [])
                
                if keypoints and scores:
                    num_frames = len(keypoints)
                    
                    # RTMW 133개 키포인트 배열 초기화
                    keypoints_array = np.zeros((num_frames, 133, 2), dtype=np.float32)
                    scores_array = np.zeros((num_frames, 133), dtype=np.float32)
                    
                    for frame_idx, (frame_kpts, frame_scores) in enumerate(zip(keypoints, scores)):
                        # 첫 번째 사람만 사용
                        if isinstance(frame_kpts, list) and len(frame_kpts) > 0:
                            person_kpts = frame_kpts[0]
                            person_scores = frame_scores[0] if len(frame_scores) > 0 else []
                            
                            # 키포인트 변환 (17개 -> 133개 매핑)
                            if isinstance(person_kpts, list) and len(person_kpts) >= 34:  # 17*2
                                # 17개 키포인트만 사용하고 나머지는 0으로
                                for joint_idx in range(min(17, 133)):
                                    x_idx = joint_idx * 2
                                    y_idx = joint_idx * 2 + 1
                                    if y_idx < len(person_kpts):
                                        keypoints_array[frame_idx, joint_idx, 0] = person_kpts[x_idx]
                                        keypoints_array[frame_idx, joint_idx, 1] = person_kpts[y_idx]
                            
                            # 스코어 변환
                            if isinstance(person_scores, list) and len(person_scores) >= 17:
                                scores_array[frame_idx, :min(17, 133)] = person_scores[:min(17, 133)]
                    
                    # 8배 스케일링 후 int32로 저장 (Streamlined 규격)
                    keypoints_scaled = np.round(keypoints_array * 8).astype(np.int32)
                    
                    pose_group.create_dataset("keypoints_scaled", data=keypoints_scaled, compression='lzf')
                    pose_group.create_dataset("scores", data=scores_array, compression='lzf')
        
        # 파일 크기 정보
        frames_size = os.path.getsize(frames_h5_path) / (1024*1024)
        poses_size = os.path.getsize(poses_h5_path) / (1024*1024)
        
        print(f"✅ 배치 {batch_idx:02d} 저장 완료:")
        print(f"   - {frames_filename}: {frames_size:.1f}MB")
        print(f"   - {poses_filename}: {poses_size:.1f}MB")
        print(f"   - 총 용량: {frames_size + poses_size:.1f}MB")
        
    except Exception as e:
        print(f"💥 배치 {batch_idx:02d} 저장 실패: {e}")
        traceback.print_exc()
        raise

def process_full_folder_production(
    input_folder: str,
    output_folder: str,
    batch_size: int = 250,
    processing_batch_size: int = 128,
    max_vram_usage: float = 0.75
) -> Dict:
    """전체 폴더를 250개씩 배치로 나누어 Production 처리"""
    
    print("🚀 Production 전체 폴더 처리 시작")
    print("=" * 80)
    print(f"📁 입력 폴더: {input_folder}")
    print(f"📁 출력 폴더: {output_folder}")
    print(f"📦 배치 크기: {batch_size}개")
    print(f"⚙️ 처리 배치 크기: {processing_batch_size}")
    print(f"🖥️ 최대 VRAM 사용률: {max_vram_usage*100}%")
    
    start_total_time = time.time()
    
    # 출력 폴더 생성
    os.makedirs(output_folder, exist_ok=True)
    
    # 1. 모든 비디오 파일 찾기
    all_video_paths = find_all_videos_in_folder(input_folder)
    
    if not all_video_paths:
        print("❌ 처리할 비디오 파일이 없습니다.")
        return {'status': 'failed', 'reason': 'no_videos'}
    
    total_videos = len(all_video_paths)
    print(f"\n📊 발견된 총 비디오: {total_videos}개")
    
    # 2. 250개씩 배치 생성
    batches = create_batches(all_video_paths, batch_size)
    total_batches = len(batches)
    
    print(f"📦 총 배치 수: {total_batches}개")
    
    # GPU 확인
    try:
        import torch
        gpu_count = torch.cuda.device_count()
        print(f"🖥️ 사용 가능한 GPU: {gpu_count}개")
        
        if gpu_count < 2:
            print("⚠️ 듀얼 GPU가 아닙니다. 가용 GPU로 처리를 진행합니다.")
    except:
        print("⚠️ GPU 정보를 가져올 수 없습니다.")
        gpu_count = 1
    
    # Processing 설정
    config = {
        'rtmw_model_name': 'rtmw-dw-x-l_simcc-cocktail14_270e-384x288.onnx',
        'batch_size': processing_batch_size,
        'keypoint_scale': 8,
        'jpeg_quality': 90,
        'max_vram_usage': max_vram_usage
    }
    
    # 배치별 처리 결과
    batch_results = []
    successful_batches = 0
    failed_batches = 0
    
    print(f"\n🔥 배치 처리 시작...")
    print("=" * 80)
    
    for batch_idx, batch_videos in enumerate(batches):
        batch_start_time = time.time()
        
        print(f"\n📦 배치 {batch_idx:02d}/{total_batches-1:02d} 처리 시작")
        print(f"   - 비디오 수: {len(batch_videos)}개")
        print(f"   - 진행률: {(batch_idx)/total_batches*100:.1f}%")
        
        try:
            # 임시 출력 디렉토리
            temp_output_dir = os.path.join(output_folder, f"temp_batch_{batch_idx:02d}")
            os.makedirs(temp_output_dir, exist_ok=True)
            
            # 듀얼 GPU 처리 (또는 사용 가능한 GPU로)
            def batch_progress_callback(progress):
                batch_progress = (batch_idx + progress) / total_batches
                print(f"📊 전체 진행률: {batch_progress*100:.1f}% (배치 {batch_idx:02d}: {progress*100:.1f}%)")
            
            summary = process_videos_dual_gpu_async_batch(
                video_paths=batch_videos,
                output_dir=temp_output_dir,
                config=config,
                progress_callback=batch_progress_callback
            )
            
            batch_processing_time = time.time() - batch_start_time
            
            # 개별 처리 결과를 배치 결과로 수집
            current_batch_results = []
            for task_id, result_item in summary['results'].items():
                if result_item['status'] == 'completed':
                    current_batch_results.append(result_item)
            
            if current_batch_results:
                # Streamlined HDF5 배치 저장
                save_batch_to_streamlined_hdf5(current_batch_results, batch_idx, output_folder)
                
                successful_batches += 1
                
                print(f"✅ 배치 {batch_idx:02d} 완료:")
                print(f"   - 성공: {len(current_batch_results)}개")
                print(f"   - 실패: {len(batch_videos) - len(current_batch_results)}개") 
                print(f"   - 처리 시간: {batch_processing_time:.2f}초")
                print(f"   - 평균 시간: {batch_processing_time/len(batch_videos):.2f}초/비디오")
            else:
                print(f"❌ 배치 {batch_idx:02d} 처리 실패: 성공한 비디오가 없음")
                failed_batches += 1
            
            # 임시 디렉토리 정리
            try:
                import shutil
                shutil.rmtree(temp_output_dir)
            except:
                pass
            
            batch_results.append({
                'batch_idx': batch_idx,
                'video_count': len(batch_videos),
                'successful_count': len(current_batch_results),
                'failed_count': len(batch_videos) - len(current_batch_results),
                'processing_time': batch_processing_time,
                'summary': summary
            })
            
        except Exception as e:
            print(f"💥 배치 {batch_idx:02d} 처리 실패: {e}")
            traceback.print_exc()
            failed_batches += 1
            
            batch_results.append({
                'batch_idx': batch_idx,
                'video_count': len(batch_videos),
                'successful_count': 0,
                'failed_count': len(batch_videos),
                'processing_time': time.time() - batch_start_time,
                'error': str(e)
            })
        
        # 메모리 정리
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    total_time = time.time() - start_total_time
    
    # 최종 결과 정리
    total_successful_videos = sum(r.get('successful_count', 0) for r in batch_results)
    total_failed_videos = sum(r.get('failed_count', 0) for r in batch_results)
    
    print(f"\n🏁 Production 전체 처리 완료")
    print("=" * 80)
    print(f"✅ 최종 결과:")
    print(f"   - 총 배치: {total_batches}개")
    print(f"   - 성공 배치: {successful_batches}개") 
    print(f"   - 실패 배치: {failed_batches}개")
    print(f"   - 총 비디오: {total_videos}개")
    print(f"   - 성공 비디오: {total_successful_videos}개")
    print(f"   - 실패 비디오: {total_failed_videos}개")
    print(f"   - 총 처리 시간: {total_time:.2f}초 ({total_time/3600:.1f}시간)")
    print(f"   - 평균 처리 시간: {total_time/max(total_videos, 1):.2f}초/비디오")
    
    # 생성된 HDF5 파일 확인
    h5_files = [f for f in os.listdir(output_folder) if f.endswith('.h5')]
    frames_files = [f for f in h5_files if 'frames' in f]
    poses_files = [f for f in h5_files if 'poses' in f]
    
    print(f"\n💾 생성된 Streamlined HDF5 파일:")
    print(f"   - 프레임 파일: {len(frames_files)}개")
    print(f"   - 포즈 파일: {len(poses_files)}개")
    print(f"   - 네이밍 규칙: batch_XX_F_frames.h5, batch_XX_F_poses.h5")
    
    # 파일 크기 정보
    total_size = 0
    for f in h5_files:
        file_path = os.path.join(output_folder, f)
        file_size = os.path.getsize(file_path)
        total_size += file_size
    
    print(f"   - 총 파일 크기: {total_size / (1024*1024*1024):.2f}GB")
    
    # 처리 성능 정보
    if total_successful_videos > 0:
        overall_fps = total_successful_videos / max(total_time, 1)
        print(f"\n⚡ 처리 성능:")
        print(f"   - 전체 처리 속도: {overall_fps:.2f} 비디오/초")
        
        if successful_batches == total_batches:
            print("   ✅ 모든 배치가 성공적으로 처리되었습니다!")
            success_rate = 100.0
        else:
            success_rate = (successful_batches / total_batches) * 100
            print(f"   📊 배치 성공률: {success_rate:.1f}%")
        
        video_success_rate = (total_successful_videos / total_videos) * 100
        print(f"   📊 비디오 성공률: {video_success_rate:.1f}%")
    
    return {
        'status': 'completed',
        'total_batches': total_batches,
        'successful_batches': successful_batches,
        'failed_batches': failed_batches,
        'total_videos': total_videos,
        'successful_videos': total_successful_videos,
        'failed_videos': total_failed_videos,
        'total_time': total_time,
        'batch_results': batch_results,
        'output_files': {
            'frames_files': frames_files,
            'poses_files': poses_files,
            'total_size_gb': total_size / (1024*1024*1024)
        }
    }

def main_production():
    """Production 메인 함수 - 전체 폴더를 250개씩 배치 처리"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Batch Fast Multi-ONNX Processor - Production")
    parser.add_argument("--input_folder", type=str, required=True,
                        help="입력 비디오 폴더 경로")
    parser.add_argument("--output_folder", type=str, required=True, 
                        help="출력 HDF5 폴더 경로")
    parser.add_argument("--batch_size", type=int, default=250,
                        help="배치 크기 (기본값: 250)")
    parser.add_argument("--processing_batch_size", type=int, default=128,
                        help="GPU 처리 배치 크기 (기본값: 128)")
    parser.add_argument("--max_vram_usage", type=float, default=0.75,
                        help="최대 VRAM 사용률 (기본값: 0.75)")
    
    args = parser.parse_args()
    
    print("🚀 Production Mode - Batch Fast Multi-ONNX Processor")
    print("=" * 80)
    print(f"📁 입력 폴더: {args.input_folder}")
    print(f"📁 출력 폴더: {args.output_folder}")
    print(f"📦 배치 크기: {args.batch_size}개")
    print(f"⚙️ 처리 배치: {args.processing_batch_size}")
    print(f"🖥️ VRAM 사용률: {args.max_vram_usage*100}%")
    
    try:
        result = process_full_folder_production(
            input_folder=args.input_folder,
            output_folder=args.output_folder,
            batch_size=args.batch_size,
            processing_batch_size=args.processing_batch_size,
            max_vram_usage=args.max_vram_usage
        )
        
        if result['status'] == 'completed':
            print("\n🎉 Production 처리 성공!")
            return 0
        else:
            print(f"\n❌ Production 처리 실패: {result.get('reason', 'unknown')}")
            return 1
            
    except KeyboardInterrupt:
        print("\n⏹️ 사용자에 의해 중단되었습니다")
        return 1
    except Exception as e:
        print(f"\n💥 Production 처리 오류: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # 명령줄 인자가 있으면 Production 모드
        exit(main_production())
    else:
        # 인자가 없으면 테스트 모드
        exit(main())


